<h1>Data Science on AWS - O'Reilly Book</h1>
<p><a href="https://www.amazon.com/Data-Science-AWS-End-End/dp/1492079391/"><img alt="Data Science on AWS" src="img/data-science-on-aws-book.png" /></a></p>
<h2>Book Outline</h2>
<p><img alt="Book Outline" src="img/outline.png" /></p>
<h1>Quick Start Workshop (4-hours)</h1>
<p><img alt="Workshop Paths" src="img/workshop_paths1.png" /></p>
<p>In this quick start hands-on workshop, you will build an end-to-end AI/ML pipeline for natural language processing with Amazon SageMaker.  You will train and tune a text classifier to predict the star rating (1 is bad, 5 is good) for product reviews using the state-of-the-art <a href="https://arxiv.org/abs/1810.04805">BERT</a> model for language representation.  To build our BERT-based NLP text classifier, you will use a product reviews dataset where each record contains some review text and a star rating (1-5).</p>
<h2>Quick Start Workshop Learning Objectives</h2>
<p>Attendees will learn how to do the following:
<em> Ingest data into S3 using Amazon Athena and the Parquet data format
</em> Visualize data with pandas, matplotlib on SageMaker notebooks
<em> Detect statistical data bias with SageMaker Clarify
</em> Perform feature engineering on a raw dataset using Scikit-Learn and SageMaker Processing Jobs
<em> Store and share features using SageMaker Feature Store
</em> Train and evaluate a custom BERT model using TensorFlow, Keras, and SageMaker Training Jobs
<em> Evaluate the model using SageMaker Processing Jobs
</em> Track model artifacts using Amazon SageMaker ML Lineage Tracking
<em> Run model bias and explainability analysis with SageMaker Clarify
</em> Register and version models using SageMaker Model Registry
<em> Deploy a model to a REST endpoint using SageMaker Hosting and SageMaker Endpoints
</em> Automate ML workflow steps by building end-to-end model pipelines using SageMaker Pipelines</p>
<h1>Extended Workshop (8-hours)</h1>
<p><img alt="Workshop Paths" src="img/workshop_paths2.png" /></p>
<p>In the extended hands-on workshop, you will get hands-on with advanced model training and deployment techniques such as hyper-parameter tuning, A/B testing, and auto-scaling.  You will also setup a real-time, streaming analytics and data science pipeline to perform window-based aggregations and anomaly detection.</p>
<h2>Extended Workshop Learning Objectives</h2>
<p>Attendees will learn how to do the following:
<em> Perform automated machine learning (AutoML) to find the best model from just your dataset with low-code
</em> Find the best hyper-parameters for your custom model using SageMaker Hyper-parameter Tuning Jobs
<em> Deploy multiple model variants into a live, production A/B test to compare online performance, live-shift prediction traffic, and autoscale the winning variant using SageMaker Hosting and SageMaker Endpoints
</em> Setup a streaming analytics and continuous machine learning application using Amazon Kinesis and SageMaker</p>
<h1>Workshop Instructions</h1>
<h2>1. Login to AWS Console</h2>
<p><img alt="Console" src="img/aws_console.png" /></p>
<h2>2. Launch SageMaker Studio</h2>
<p>Open the <a href="https://console.aws.amazon.com/console/home">AWS Management Console</a></p>
<p>Configure IAM to run the workshop.</p>
<p><img alt="IAM 1" src="img/sagemaker-iam-1.png" /></p>
<p><img alt="IAM 2" src="img/sagemaker-iam-2.png" /></p>
<p><img alt="IAM 3" src="img/sagemaker-iam-3.png" /></p>
<p><img alt="Back to SageMaker" src="img/alt_back_to_sagemaker_8.png" /></p>
<p>In the AWS Console search bar, type <code>SageMaker</code> and select <code>Amazon SageMaker</code> to open the service console.</p>
<p><img alt="Notebook Instances" src="img/stu_notebook_instances_9.png" /></p>
<p><img alt="Quick Start" src="img/sm-quickstart-iam-existing.png" /></p>
<p><img alt="Pending Studio" src="img/studio_pending.png" /></p>
<p><img alt="Open Studio" src="img/studio_open.png" /></p>
<p><img alt="Loading Studio" src="img/studio_loading.png" /></p>
<h2>3. Launch a New Terminal within Studio</h2>
<p>Click <code>File</code> &gt; <code>New</code> &gt; <code>Terminal</code> to launch a terminal in your Jupyter instance.</p>
<p><img alt="Terminal Studio" src="img/studio_terminal.png" /></p>
<h2>4. Clone this GitHub Repo in the Terminal</h2>
<p>Within the Terminal, run the following:</p>
<p><code>cd ~ &amp;&amp; git clone https://github.com/data-science-on-aws/workshop</code></p>
<p>If you see an error like the following, just re-run the command again until it works:
```
fatal: Unable to create '/home/sagemaker-user/workshop/.git/index.lock': File exists.</p>
<p>Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
```
<em>Note:  This is not a fatal error ^^ above ^^.  Just re-run the command again until it works.</em></p>
<h2>5. Start the Workshop!</h2>
<p>Navigate to <code>workshop/00_quickstart/</code> in SageMaker Studio and start the workshop!</p>
<p><em>You may need to refresh your browser if you don't see the new <code>workshop/</code> directory.</em></p>
<p><img alt="Start Workshop" src="img/studio_start_workshop.png" /></p>