{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of constructing a binary classifier for a set of binary features. This problem has a host of practical applications. For example, the binary features can be interpreted as readings from a network of sensors or a fleet of autonomous vehicles and the labels can indicate an overall state of the network / vehicle (safe or fail). In general, these systems have a complex behavior and cannot be modeled exactly to specify the feature-label mapping $f$. Machine learning solutions are deployed ubiquitously to “learn” the  mapping $f$ by using e.g. supervised learning and training sets. Here, we explore how quantum computers can be utilized to solve this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to assign binary labels ${\\bf y}=\\{0,1\\}$ to a set of $N$-bit feature vectors ${\\bf x}_i=\\{x_{i1},\\cdots,x_{iN}\\}$ ($x_{ij}=\\{0,1\\}$). We assume that there is an unknown Boolean function $f({\\bf x})$ that maps a feature vector onto a corresponding binary label ${\\bf y}$ i.e. ${\\bf y}=f({\\bf x})$. We do not know $f$ but, given some fitness metric $L$ and a training set $T$ of observed features ${\\bf x}_i$ and corresponding labels ${\\bf y}_i$ ($T=\\{{\\bf x}_i, {\\bf y}_i\\}$,$i=1,M$), we would like to construct a quantum circuit $\\mathcal{C}$ such that it minimizes $L$ and reproduces the labels of the set T with the total error $\\le \\epsilon$ for some pre-specified $\\epsilon\\ge 0$. Then we can use the circuit $\\mathcal{C}$ to classify features outside of the training set $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cast the binary classification problem into a form acceptable by a quantum computer, we need to\n",
    "\n",
    "- Specify a mapping of classical features $\\{{\\bf x}_i\\}$ onto quantum states of a register of qubits $\\{|\\psi_i\\rangle \\}$.\n",
    "- Specify a quantum circuit $\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})$ (a sequence of elementary single- and two-qubit gates) that transforms the input states $\\{|\\psi_i\\rangle \\}$ into output states $\\{|\\phi_i\\rangle \\}$ ($|\\phi_i\\rangle = \\mathcal{C}|\\psi_i\\rangle $). The circuit $\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})$ depends on classical parameters $\\{\\vec{\\theta},\\vec{\\phi}\\}$ that can be adjusted to change the output $\\{|\\phi_i\\rangle \\}$ .\n",
    "- Specify a measurement (Hermitian operator $M$) to perform on the output states $\\{|\\phi_i\\rangle \\}$.\n",
    "\n",
    "If the form of the function $f$ that maps features $\\{{\\bf x}_i\\}$ into labels ${\\bf y}=f({\\bf x})$ were known then we could construct a corresponding quantum circuit $\\mathcal{C}_f$, such that $\\mathcal{C}_f∣\\psi_i\\rangle∣0⟩=∣\\psi_i\\rangle∣f({\\bf x})\\rangle$ for all binary features ${\\bf x}$, using, e.g., basic quantum arithmetic (adder) circuits. A more realistic scenario is when $f$ is unknown. In this case we will construct a quantum circuit $\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})$, where single-qubit and two-qubit quantum gates depend on continuous parameters $\\vec{\\theta} = \\{\\theta_1,\\cdots,\\theta_n\\}$ and $\\vec{\\phi} = \\{\\phi_1,\\cdots,\\phi_m\\}$ respectively, such that $\\mathcal{C}$ approximates the action of $\\mathcal{C}_f$ on features from the training set $T$ for some suitable parameter values $\\{\\vec{\\theta}_0,\\vec{\\phi}_0\\}$. The problem of finding parameters $\\{\\vec{\\theta}_0,\\vec{\\phi}_0\\}$ can be solved by using gradient training techniques i.e. by classical minimization of a loss function. For example, the loss function can be defined as the total distance between the output states of the quantum neural net $\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})$ and the states of the training set $T$. In this case the training task is\n",
    "\n",
    "- ${\\rm minimize}\\sum\\limits_{i\\in T}\\|\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})|\\psi_i\\rangle|0\\rangle-|\\psi_i\\rangle|{\\bf y}_i\\rangle\\|^2 $,\n",
    "\n",
    "over all values of $\\{\\vec{\\theta},\\vec{\\phi}\\}$. We solve this training task by evaluating the loss function using quantum backend and updating parameters $\\{\\vec{\\theta},\\vec{\\phi}\\}$ classically in a e.g. a steepest descent loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping binary features onto quantum states of qubits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to map classical data onto quantum states of qubits. Arguably the simplest way, given the binary nature of our features, is to map $x_{ij}$ -- the $j$-th bit of the ${\\bf x}_i$ feature bit string -- to the correspondent quantum state of the $j$-th qubit $∣x_{ij}\\rangle$. Then ${\\bf x}_i = \\{x_{i1},\\cdots,x_{iN}\\}$ will be mapped onto the $N$-qubit state $∣{\\bf x}_i\\rangle=∣x_{i1}\\rangle\\otimes\\cdots\\otimes|x_{iN}\\rangle=∣x_{i1},\\cdots,x_{iN}\\rangle$. Similarly, we will map the labels ${\\bf y}_i$ onto the state $|{\\bf y}_i\\rangle$ of the label qubit. For example, the feature-label tuple $\\{{\\bf x}_i=00101010,{\\bf y}_i=0\\}$ will be represented by the quantum state $∣\\psi_i\\rangle =∣00101010\\rangle∣0\\rangle$. Here is how one could construct a quantum circuit that prepares the state $∣\\psi_i\\rangle$ using Amazon Braket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T  : |0|\n",
      "        \n",
      "q2 : -X-\n",
      "        \n",
      "q4 : -X-\n",
      "        \n",
      "q6 : -X-\n",
      "\n",
      "T  : |0|\n"
     ]
    }
   ],
   "source": [
    "# Import Braket libraries\n",
    "from braket.circuits import Circuit\n",
    "from braket.aws import AwsDevice\n",
    "\n",
    "# A function that converts a bit string bitStr into a quantum circuit\n",
    "def bit_string2circuit(bitStr):\n",
    "   \n",
    "    circuit = Circuit()\n",
    "    for ind in range(len(bitStr)):\n",
    "        if bitStr[ind]=='1':\n",
    "            circuit.x(ind)\n",
    "            \n",
    "    return circuit\n",
    "    \n",
    "# provide a feature string from the example above\n",
    "feature = '00101010'\n",
    "\n",
    "# print quantum circuit that prepares corresponding quantum state \n",
    "print(bit_string2circuit(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Quantum Neural Networks and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Parity-based labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first example, let us assume that labels ${\\bf y}_i$ are generated by a Boolean function $f({\\bf x}_i) = (\\sum\\limits_{j=1}^{N}x_{ij})\\ {\\rm mod}\\ 2$. We will generate $M$ random $N$-bit feature strings and assign them labels according to $f$. This will be our training set $T$. For the quantum neural network $\\mathcal{C}(\\{\\vec{\\theta},\\vec{\\phi}\\})$ that we will train to perform the classification, we will use the design layout depicted in Figure 1. It is has $4N+1$ classical parameters defining: $N$ two-qubit gates $XX(\\phi_j) = e^{-i\\phi_j \\hat{X}_j\\hat{X}_{N+1}}$ and $3N+1$ single-qubit gates $R_{x}(\\theta_k) = e^{-i\\theta_k\\hat{X}_j}$ and $R_{y}(\\theta_m) = e^{-i\\theta_m\\hat{Y}_j}$. We will use the $N+1$-th qubit to compute the label value after the quantum neural net acted on the initial state $|x_{i1},\\cdots,x_{iN}\\rangle|0\\rangle$. In particular, we will encode the label in the expectation value $\\langle\\hat{Z}\\rangle(\\{\\vec{\\theta},\\vec{\\phi}\\}) =\\langle 0,{\\bf x}_i|\\tilde{\\mathcal{C}}^{\\dagger}(\\{\\vec{\\theta},\\vec{\\phi}\\})\\hat{Z}_{N+1}\\tilde{\\mathcal{C}}(\\{\\vec{\\theta},\\vec{\\phi}\\})|{\\bf x}_i,0\\rangle$ of Pauli $\\hat{Z}$ operator on the $N+1$-th qubit.  By definition, given the feature ${\\bf x}_i$, $\\langle\\hat{Z}\\rangle$ is a continuous function of the quantum neural net parameters $\\{\\vec{\\theta},\\vec{\\phi}\\}$ in the range $[−1,1]$. In the training of the quantum neural net circuit $\\mathcal{C}$ our goal is to find a set of parameters $\\{\\vec{\\theta}_o,\\vec{\\phi}_o\\}$ that for each feature in the training set $T$ the label value ${\\bf y}_i$ is close to $\\frac{1-\\langle\\hat{Z}\\rangle(\\{\\vec{\\theta}_o,\\vec{\\phi}_o\\})}{2}$. To achieve this, we will minimize the log loss function $L(\\{\\vec{\\theta},\\vec{\\phi}\\}) $ defined as,\n",
    "\n",
    "$L(\\{\\vec{\\theta},\\vec{\\phi}\\})=-\\sum\\limits_{i=1}^{M}{\\bf y}_i\\log(\\frac{1-\\langle\\hat{Z}\\rangle (\\{\\vec{\\theta},\\vec{\\phi}\\} )}{2})+(1-{\\bf y}_i)\\log(\\frac{1+\\langle\\hat{Z}\\rangle(\\{\\vec{\\theta},\\vec{\\phi}\\})}{2})$.\n",
    "\n",
    "We can use quantum backends to evaluate $L(\\{\\vec{\\theta},\\vec{\\phi}\\})$ and a classical optimizer (e.g. from scipy.optimize ) to minimize it. Here is how we can do it using Braket local simulator as a backend."
   ]
  },
  {
   "attachments": {
    "Binary%20Classifier%20QML_Parity.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Binary%20Classifier%20QML_Parity.png](attachment:Binary%20Classifier%20QML_Parity.png \"Figure 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us construct the quantum neural net circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard numpy libraries and optimizers\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Braket imports\n",
    "from braket.circuits import Circuit, Gate, Instruction, circuit, Observable\n",
    "from braket.aws import AwsDevice, AwsQuantumTask\n",
    "from braket.devices import LocalSimulator\n",
    "\n",
    "# set Braket backend to local simulator (can be changed to other backends)\n",
    "device = LocalSimulator() \n",
    "\n",
    "# Quantum Neural Net from Figure 2 implemented in Braket\n",
    "# Inputs: bitStr - feature bit string (e.g. '01010101')\n",
    "#         pars - array of parameters theta and phi (see Figure 2 for more details) \n",
    "\n",
    "def QNN(bitStr,pars):\n",
    "    ## size of the quantum neural net circuit\n",
    "    nQbts = len(bitStr) + 1 # extra qubit is allocated for the label \n",
    "    \n",
    "    ## initilize the circuit\n",
    "    qnn = Circuit()\n",
    "    \n",
    "    ## add XX gate between qubit i and the label qubit, \n",
    "    ## single-qubit X and Y rotations, \n",
    "    ## and initilaize the input state to the one specified by bitStr\n",
    "    qnn.rx(nQbts-1,pars[0])\n",
    "    for ind in range(nQbts-1):\n",
    "        angles = pars[4*ind + 1:4*ind+1+4]\n",
    "        if bitStr[ind] == '1': # by default Braket sets input states to '0', \n",
    "                               # qnn.x(ind) flips qubit number ind to state |1\\ \n",
    "            qnn.x(ind)\n",
    "        qnn.ry(ind,angles[0]).xx(ind, nQbts-1, angles[1]).rx(ind,angles[2]).ry(ind,angles[3])\n",
    "    \n",
    "    ## add Z observable to the label qubit\n",
    "    observZ = Observable.Z()\n",
    "    qnn.expectation(observZ, target=[nQbts-1]) \n",
    "    \n",
    "    return qnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will code up the log loss function $L(\\{\\vec{\\theta},\\vec{\\phi}\\})$ that we will minimize to train our binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that computes the label of a given feature bit sting bitStr\n",
    "\n",
    "def parity(bitStr):\n",
    "    count = 0\n",
    "    for ind in range(len(bitStr)):\n",
    "        if bitStr[ind]=='1':\n",
    "            count+=1            \n",
    "    return count%2\n",
    "\n",
    "## Log loss function L(theta,phi) for a given training set trainSet\n",
    "## inputs: trainSet - array of feature bit strings e.g. ['0101','1110','0000'] \n",
    "##         pars - quantum neural net parameters theta and phi (See Figure 2)\n",
    "##         device -  Braket backend that will compute the log loss\n",
    "def cost(trainSet,pars,device):\n",
    "    cost = 0.0\n",
    "    for ind in range(np.size(trainSet)):  \n",
    "        ## run QNN on Braket device\n",
    "        task = device.run(QNN(trainSet[ind],pars), shots=0) \n",
    "        ## retrieve the run results <Z>\n",
    "        result = task.result()\n",
    "          \n",
    "        if parity(trainSet[ind])==0:\n",
    "            cost += -np.log2(1.0-0.5*(1.0-result.values[0]))\n",
    "        else:\n",
    "            cost += -np.log2(0.5*(1.0-result.values[0]))\n",
    "    print (\"Current value of the loss function: \", cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together we can now train our quantum neural net to reproduce binary classification of a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476457787\n",
      "Current value of the loss function:  11.063528474826576\n",
      "Current value of the loss function:  11.063528469164469\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528475965331\n",
      "Current value of the loss function:  11.063528477742825\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528480882711\n",
      "Current value of the loss function:  11.063528472806594\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528477397838\n",
      "Current value of the loss function:  11.0635284774927\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528475975446\n",
      "Current value of the loss function:  11.063528479365827\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528473305386\n",
      "Current value of the loss function:  11.063528481154503\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528470207148\n",
      "Current value of the loss function:  11.063528481582265\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528474822203\n",
      "Current value of the loss function:  11.063528477537998\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528475608045\n",
      "Current value of the loss function:  11.063528474998469\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365127\n",
      "Current value of the loss function:  11.063528476480679\n",
      "Current value of the loss function:  11.063528481966578\n",
      "Current value of the loss function:  11.063528476365128\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  11.063528476365125\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974730515528\n",
      "Current value of the loss function:  10.668974734420347\n",
      "Current value of the loss function:  10.668974731315325\n",
      "Current value of the loss function:  10.668974728899357\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974730193419\n",
      "Current value of the loss function:  10.668974727592433\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974733831357\n",
      "Current value of the loss function:  10.668974735845216\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899357\n",
      "Current value of the loss function:  10.668974727153902\n",
      "Current value of the loss function:  10.668974728731971\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728884438\n",
      "Current value of the loss function:  10.668974732492101\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899357\n",
      "Current value of the loss function:  10.668974729214296\n",
      "Current value of the loss function:  10.668974722348166\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899357\n",
      "Current value of the loss function:  10.668974729146838\n",
      "Current value of the loss function:  10.668974733664395\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974735628094\n",
      "Current value of the loss function:  10.668974723432113\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728386656\n",
      "Current value of the loss function:  10.668974730248296\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974727715831\n",
      "Current value of the loss function:  10.668974731416869\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  10.668974728899357\n",
      "Current value of the loss function:  10.668974728899355\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675886985884\n",
      "Current value of the loss function:  9.610675900243272\n",
      "Current value of the loss function:  9.610675902231089\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675889168732\n",
      "Current value of the loss function:  9.610675892058925\n",
      "Current value of the loss function:  9.610675886802111\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675889168732\n",
      "Current value of the loss function:  9.610675889622247\n",
      "Current value of the loss function:  9.610675912865874\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675880714577\n",
      "Current value of the loss function:  9.610675878584217\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675888935408\n",
      "Current value of the loss function:  9.610675896860027\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675899709946\n",
      "Current value of the loss function:  9.610675850259073\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675892315122\n",
      "Current value of the loss function:  9.61067589582907\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.610675891658992\n",
      "Current value of the loss function:  9.610675869129205\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.610675889168732\n",
      "Current value of the loss function:  9.610675889711548\n",
      "Current value of the loss function:  9.610675895232333\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.61067588916873\n",
      "Current value of the loss function:  9.61067588752727\n",
      "Current value of the loss function:  9.610675893305691\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  9.610675889168732\n",
      "Current value of the loss function:  9.610675889168729\n",
      "Current value of the loss function:  17.29985311051973\n",
      "Current value of the loss function:  17.29985308758109\n",
      "Current value of the loss function:  17.299853110344465\n",
      "Current value of the loss function:  17.29985306677366\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.29985310122757\n",
      "Current value of the loss function:  17.299853033390924\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853135708794\n",
      "Current value of the loss function:  17.299853043868755\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.29985311051973\n",
      "Current value of the loss function:  17.299853122731687\n",
      "Current value of the loss function:  17.299853079373353\n",
      "Current value of the loss function:  17.299853110519724\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853083271913\n",
      "Current value of the loss function:  17.299853184502588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853115715674\n",
      "Current value of the loss function:  17.29985314091384\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519724\n",
      "Current value of the loss function:  17.299853140426954\n",
      "Current value of the loss function:  17.29985302289657\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.29985311284175\n",
      "Current value of the loss function:  17.299853056102936\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853099578083\n",
      "Current value of the loss function:  17.29985300418328\n",
      "Current value of the loss function:  17.29985311051973\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.29985311104809\n",
      "Current value of the loss function:  17.299853212605075\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.299853110519727\n",
      "Current value of the loss function:  17.29985311051973\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.379586219557973\n",
      "Current value of the loss function:  9.379586234573638\n",
      "Current value of the loss function:  9.379586238831099\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.37958622703391\n",
      "Current value of the loss function:  9.379586222357062\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586224241903\n",
      "Current value of the loss function:  9.379586222523189\n",
      "Current value of the loss function:  9.379586253832452\n",
      "Current value of the loss function:  9.379586224241903\n",
      "Current value of the loss function:  9.379586224241903\n",
      "Current value of the loss function:  9.379586213296273\n",
      "Current value of the loss function:  9.379586207475125\n",
      "Current value of the loss function:  9.379586224241903\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586224042992\n",
      "Current value of the loss function:  9.379586231170096\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586237860545\n",
      "Current value of the loss function:  9.379586176255978\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586227429574\n",
      "Current value of the loss function:  9.37958623175272\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586222911609\n",
      "Current value of the loss function:  9.379586198897721\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.379586225376437\n",
      "Current value of the loss function:  9.379586231275859\n",
      "Current value of the loss function:  9.3795862242419\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.379586222889799\n",
      "Current value of the loss function:  9.379586228094672\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  9.379586224241903\n",
      "Current value of the loss function:  9.379586224241901\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865880189923\n",
      "Current value of the loss function:  13.722865863202005\n",
      "Current value of the loss function:  13.72286591485879\n",
      "Current value of the loss function:  13.722865862140955\n",
      "Current value of the loss function:  13.722865862140956\n",
      "Current value of the loss function:  13.722865853440517\n",
      "Current value of the loss function:  13.722865775453938\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862140951\n",
      "Current value of the loss function:  13.722865882258668\n",
      "Current value of the loss function:  13.722865843059449\n",
      "Current value of the loss function:  13.722865862140951\n",
      "Current value of the loss function:  13.722865862140956\n",
      "Current value of the loss function:  13.722865874807278\n",
      "Current value of the loss function:  13.72286584967778\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865845935887\n",
      "Current value of the loss function:  13.722865795257988\n",
      "Current value of the loss function:  13.722865862140956\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865875125605\n",
      "Current value of the loss function:  13.722865858525\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862140951\n",
      "Current value of the loss function:  13.722865920324889\n",
      "Current value of the loss function:  13.722865813341745\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865854548555\n",
      "Current value of the loss function:  13.722865856046962\n",
      "Current value of the loss function:  13.72286586214095\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865889419504\n",
      "Current value of the loss function:  13.722865869717822\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  13.722865862721644\n",
      "Current value of the loss function:  13.722865821601571\n",
      "Current value of the loss function:  13.722865862140956\n",
      "Current value of the loss function:  13.722865862140951\n",
      "Current value of the loss function:  13.722865862140953\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.86545800921657\n",
      "Current value of the loss function:  8.865458021768747\n",
      "Current value of the loss function:  8.865458033292931\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458015888567\n",
      "Current value of the loss function:  8.865458002572293\n",
      "Current value of the loss function:  8.865458012717847\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458010359987\n",
      "Current value of the loss function:  8.865458048876969\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717847\n",
      "Current value of the loss function:  8.86545799692885\n",
      "Current value of the loss function:  8.865457982894993\n",
      "Current value of the loss function:  8.865458012717847\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.86545801285858\n",
      "Current value of the loss function:  8.865458005492739\n",
      "Current value of the loss function:  8.865458012717847\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.86545802869931\n",
      "Current value of the loss function:  8.865457951718454\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458011337054\n",
      "Current value of the loss function:  8.86545802342328\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458007736533\n",
      "Current value of the loss function:  8.865457981325829\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458017123416\n",
      "Current value of the loss function:  8.865458025450723\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458011367664\n",
      "Current value of the loss function:  8.86545801015641\n",
      "Current value of the loss function:  8.865458012717845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  8.865458012717845\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.391714165674255\n",
      "Current value of the loss function:  17.39171417649728\n",
      "Current value of the loss function:  17.391714235014206\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.391714150125885\n",
      "Current value of the loss function:  17.391714083285617\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.391714138482836\n",
      "Current value of the loss function:  17.391714099368023\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.391714164480035\n",
      "Current value of the loss function:  17.391714109880162\n",
      "Current value of the loss function:  17.391714151430072\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.39171407000851\n",
      "Current value of the loss function:  17.391714179649135\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.391714151430072\n",
      "Current value of the loss function:  17.39171415117442\n",
      "Current value of the loss function:  17.391714130076313\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.391714151430072\n",
      "Current value of the loss function:  17.391714131260148\n",
      "Current value of the loss function:  17.391714024781464\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.39171415130843\n",
      "Current value of the loss function:  17.391714127310753\n",
      "Current value of the loss function:  17.391714151430072\n",
      "Current value of the loss function:  17.391714151430072\n",
      "Current value of the loss function:  17.39171413996535\n",
      "Current value of the loss function:  17.39171400875129\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.391714146705187\n",
      "Current value of the loss function:  17.391714275837053\n",
      "Current value of the loss function:  17.391714151430076\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  17.39171415143008\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523423908114\n",
      "Current value of the loss function:  8.698523430822613\n",
      "Current value of the loss function:  8.698523449114203\n",
      "Current value of the loss function:  8.698523422182356\n",
      "Current value of the loss function:  8.698523422182358\n",
      "Current value of the loss function:  8.69852342586557\n",
      "Current value of the loss function:  8.698523399458592\n",
      "Current value of the loss function:  8.698523422182358\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523421054292\n",
      "Current value of the loss function:  8.698523454932921\n",
      "Current value of the loss function:  8.698523422182356\n",
      "Current value of the loss function:  8.698523422182358\n",
      "Current value of the loss function:  8.698523406265522\n",
      "Current value of the loss function:  8.698523390749854\n",
      "Current value of the loss function:  8.698523422182358\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342201048\n",
      "Current value of the loss function:  8.698523398731803\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852343645386\n",
      "Current value of the loss function:  8.698523362103186\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523417737636\n",
      "Current value of the loss function:  8.698523432075463\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523418183935\n",
      "Current value of the loss function:  8.698523393598249\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523429810638\n",
      "Current value of the loss function:  8.698523440641594\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.698523422182358\n",
      "Current value of the loss function:  8.69852342056723\n",
      "Current value of the loss function:  8.698523411364853\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.69852342218236\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518857896247\n",
      "Current value of the loss function:  8.331518863430318\n",
      "Current value of the loss function:  8.331518888621932\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518859939875\n",
      "Current value of the loss function:  8.331518820790315\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855044365\n",
      "Current value of the loss function:  8.33151888717511\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518838830604\n",
      "Current value of the loss function:  8.331518825930406\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.33151885438907\n",
      "Current value of the loss function:  8.331518818566593\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518865212688\n",
      "Current value of the loss function:  8.331518793841308\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518847786255\n",
      "Current value of the loss function:  8.331518860206574\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.33151885354995\n",
      "Current value of the loss function:  8.331518824205242\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.33151886301377\n",
      "Current value of the loss function:  8.331518878464665\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518853306566\n",
      "Current value of the loss function:  8.331518837570181\n",
      "Current value of the loss function:  8.331518855007584\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  8.331518855007586\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.04042118680406\n",
      "Current value of the loss function:  10.040421192863459\n",
      "Current value of the loss function:  10.040421277570687\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421190581682\n",
      "Current value of the loss function:  10.040421115768673\n",
      "Current value of the loss function:  10.040421191999364\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421203611963\n",
      "Current value of the loss function:  10.040421202398589\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421198896663\n",
      "Current value of the loss function:  10.04042120978565\n",
      "Current value of the loss function:  10.040421191999364\n",
      "Current value of the loss function:  10.040421191999364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  10.040421187507233\n",
      "Current value of the loss function:  10.04042112640641\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421197807213\n",
      "Current value of the loss function:  10.040421138686334\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421204007734\n",
      "Current value of the loss function:  10.040421112723447\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421192320924\n",
      "Current value of the loss function:  10.040421155735611\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421204034715\n",
      "Current value of the loss function:  10.040421223287318\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421191999368\n",
      "Current value of the loss function:  10.040421192180359\n",
      "Current value of the loss function:  10.04042112940429\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  10.040421191999366\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557184744707\n",
      "Current value of the loss function:  8.132557193983395\n",
      "Current value of the loss function:  8.13255723118974\n",
      "Current value of the loss function:  8.132557186255523\n",
      "Current value of the loss function:  8.132557186255527\n",
      "Current value of the loss function:  8.132557191240881\n",
      "Current value of the loss function:  8.13255714282712\n",
      "Current value of the loss function:  8.132557186255521\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186318698\n",
      "Current value of the loss function:  8.1325572204351\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255523\n",
      "Current value of the loss function:  8.132557173738569\n",
      "Current value of the loss function:  8.132557167800368\n",
      "Current value of the loss function:  8.132557186255523\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557185107558\n",
      "Current value of the loss function:  8.132557141962733\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557194152241\n",
      "Current value of the loss function:  8.132557124037348\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255523\n",
      "Current value of the loss function:  8.1325571812101\n",
      "Current value of the loss function:  8.13255717672203\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557184849514\n",
      "Current value of the loss function:  8.132557151464084\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557195703527\n",
      "Current value of the loss function:  8.13255721495257\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557184739445\n",
      "Current value of the loss function:  8.132557158187826\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.132557186255525\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534689657036\n",
      "Current value of the loss function:  8.18953465308719\n",
      "Current value of the loss function:  8.18953471376341\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.18953465179547\n",
      "Current value of the loss function:  8.189534611926197\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534642689008\n",
      "Current value of the loss function:  8.189534635291212\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.18953464847244\n",
      "Current value of the loss function:  8.189534634140733\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534647869372\n",
      "Current value of the loss function:  8.189534585895732\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534654653464\n",
      "Current value of the loss function:  8.189534616959785\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534656185062\n",
      "Current value of the loss function:  8.189534629932131\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652244793\n",
      "Current value of the loss function:  8.189534653229906\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534658995811\n",
      "Current value of the loss function:  8.189534675290108\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652204854\n",
      "Current value of the loss function:  8.189534619028603\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  8.189534652257816\n",
      "Current value of the loss function:  8.189534652257814\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655728509212\n",
      "Current value of the loss function:  7.806655718207589\n",
      "Current value of the loss function:  7.806655769705054\n",
      "Current value of the loss function:  7.806655713498317\n",
      "Current value of the loss function:  7.806655713498317\n",
      "Current value of the loss function:  7.806655716333596\n",
      "Current value of the loss function:  7.806655672175014\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655709913633\n",
      "Current value of the loss function:  7.806655727952263\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.8066557048496295\n",
      "Current value of the loss function:  7.80665569564515\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655711077587\n",
      "Current value of the loss function:  7.806655655955288\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655717763956\n",
      "Current value of the loss function:  7.8066556600793655\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498317\n",
      "Current value of the loss function:  7.806655708612231\n",
      "Current value of the loss function:  7.806655698069319\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713518918\n",
      "Current value of the loss function:  7.806655694303923\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.80665572229315\n",
      "Current value of the loss function:  7.806655743120562\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  7.806655712853635\n",
      "Current value of the loss function:  7.8066556797579745\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.806655713498318\n",
      "Current value of the loss function:  7.806655713498319\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.40857634332832\n",
      "Current value of the loss function:  7.408576340216118\n",
      "Current value of the loss function:  7.408576376209699\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.408576341720387\n",
      "Current value of the loss function:  7.40857628490188\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.408576332534519\n",
      "Current value of the loss function:  7.408576358705741\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.408576339045479\n",
      "Current value of the loss function:  7.408576335218058\n",
      "Current value of the loss function:  7.4085763340602675\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.4085763390454815\n",
      "Current value of the loss function:  7.408576335516943\n",
      "Current value of the loss function:  7.408576273090855\n",
      "Current value of the loss function:  7.408576339045479\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.4085763395925195\n",
      "Current value of the loss function:  7.408576308297059\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.408576339045479\n",
      "Current value of the loss function:  7.408576333951562\n",
      "Current value of the loss function:  7.408576310887225\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.4085763390454815\n",
      "Current value of the loss function:  7.408576338980441\n",
      "Current value of the loss function:  7.4085763215104565\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.4085763390454815\n",
      "Current value of the loss function:  7.408576346035382\n",
      "Current value of the loss function:  7.408576370965632\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.40857633904548\n",
      "Current value of the loss function:  7.408576338887653\n",
      "Current value of the loss function:  7.4085763007999805\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  7.408576339045481\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137322341752\n",
      "Current value of the loss function:  6.652137313502631\n",
      "Current value of the loss function:  6.65213734981977\n",
      "Current value of the loss function:  6.652137315728677\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.6521373186790385\n",
      "Current value of the loss function:  6.652137267240287\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137307652454\n",
      "Current value of the loss function:  6.652137333708574\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137312769965\n",
      "Current value of the loss function:  6.65213731214221\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137313343128\n",
      "Current value of the loss function:  6.65213725523161\n",
      "Current value of the loss function:  6.65213731572868\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.6521373158919195\n",
      "Current value of the loss function:  6.652137285406374\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137307983306\n",
      "Current value of the loss function:  6.652137292679075\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137314500475\n",
      "Current value of the loss function:  6.652137304177754\n",
      "Current value of the loss function:  6.6521373157286785\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137319093569\n",
      "Current value of the loss function:  6.652137345576629\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137315782597\n",
      "Current value of the loss function:  6.65213727419733\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  6.652137315728679\n",
      "Current value of the loss function:  5.3564200923751715\n",
      "Current value of the loss function:  5.356420095152212\n",
      "Current value of the loss function:  5.356420085729352\n",
      "Current value of the loss function:  5.356420117730478\n",
      "Current value of the loss function:  5.356420092375173\n",
      "Current value of the loss function:  5.356420092375173\n",
      "Current value of the loss function:  5.3564200950515986\n",
      "Current value of the loss function:  5.356420048416138\n",
      "Current value of the loss function:  5.3564200923751715\n",
      "Current value of the loss function:  5.356420092375173\n",
      "Current value of the loss function:  5.356420086645902\n",
      "Current value of the loss function:  5.35642010556098\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420091364172\n",
      "Current value of the loss function:  5.356420084666446\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092187795\n",
      "Current value of the loss function:  5.356420036567085\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.3564200923751715\n",
      "Current value of the loss function:  5.356420092360326\n",
      "Current value of the loss function:  5.3564200689347405\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.3564200923751715\n",
      "Current value of the loss function:  5.356420084219894\n",
      "Current value of the loss function:  5.356420070657015\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092375173\n",
      "Current value of the loss function:  5.356420087920343\n",
      "Current value of the loss function:  5.356420075531606\n",
      "Current value of the loss function:  5.356420092375173\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420091656311\n",
      "Current value of the loss function:  5.356420104276014\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092384411\n",
      "Current value of the loss function:  5.356420069292138\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.356420092375172\n",
      "Current value of the loss function:  5.3564200923751715\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959564399252\n",
      "Current value of the loss function:  4.045959577652297\n",
      "Current value of the loss function:  4.045959587037139\n",
      "Current value of the loss function:  4.04595958382238\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.0459595826292745\n",
      "Current value of the loss function:  4.045959558183158\n",
      "Current value of the loss function:  4.04595958382238\n",
      "Current value of the loss function:  4.045959583822381\n",
      "Current value of the loss function:  4.045959583279425\n",
      "Current value of the loss function:  4.0459595808435385\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.04595958382238\n",
      "Current value of the loss function:  4.045959582768459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  4.045959578240074\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959593334217\n",
      "Current value of the loss function:  4.045959559158435\n",
      "Current value of the loss function:  4.045959583822381\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959583488641\n",
      "Current value of the loss function:  4.045959559909368\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959595012286\n",
      "Current value of the loss function:  4.045959568967467\n",
      "Current value of the loss function:  4.045959583822381\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959584890827\n",
      "Current value of the loss function:  4.045959559780922\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959583798897\n",
      "Current value of the loss function:  4.045959603489129\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.045959583822381\n",
      "Current value of the loss function:  4.045959583515491\n",
      "Current value of the loss function:  4.045959541485879\n",
      "Current value of the loss function:  4.045959583822381\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  4.0459595838223805\n",
      "Current value of the loss function:  2.6675400136752994\n",
      "Current value of the loss function:  2.6675399757084164\n",
      "Current value of the loss function:  2.667540012595043\n",
      "Current value of the loss function:  2.6675400142659145\n",
      "Current value of the loss function:  2.667540013675298\n",
      "Current value of the loss function:  2.6675400136752967\n",
      "Current value of the loss function:  2.6675400129653677\n",
      "Current value of the loss function:  2.667540006134959\n",
      "Current value of the loss function:  2.6675400136753\n",
      "Current value of the loss function:  2.667540013675298\n",
      "Current value of the loss function:  2.6675400150689246\n",
      "Current value of the loss function:  2.6675400202218564\n",
      "Current value of the loss function:  2.6675400136752985\n",
      "Current value of the loss function:  2.667540013675299\n",
      "Current value of the loss function:  2.667540013433634\n",
      "Current value of the loss function:  2.6675400042802986\n",
      "Current value of the loss function:  2.667540013675298\n",
      "Current value of the loss function:  2.667540013675299\n",
      "Current value of the loss function:  2.6675400229703197\n",
      "Current value of the loss function:  2.6675400175101984\n",
      "Current value of the loss function:  2.6675400136752985\n",
      "Current value of the loss function:  2.6675400136752985\n",
      "Current value of the loss function:  2.667540014833453\n",
      "Current value of the loss function:  2.6675399867695746\n",
      "Current value of the loss function:  2.6675400136752994\n",
      "Current value of the loss function:  2.667540013675299\n",
      "Current value of the loss function:  2.6675400221440477\n",
      "Current value of the loss function:  2.6675399983857826\n",
      "Current value of the loss function:  2.6675400136752985\n",
      "Current value of the loss function:  2.6675400136752976\n",
      "Current value of the loss function:  2.6675400113866248\n",
      "Current value of the loss function:  2.667540033439783\n",
      "Current value of the loss function:  2.6675400136752994\n",
      "Current value of the loss function:  2.6675400136752985\n",
      "Current value of the loss function:  2.66754001531739\n",
      "Current value of the loss function:  2.667540006914538\n",
      "Current value of the loss function:  2.6675400136753\n",
      "Current value of the loss function:  2.667540013675299\n",
      "Current value of the loss function:  2.667540013909237\n",
      "Current value of the loss function:  2.667540003312973\n",
      "Current value of the loss function:  2.6675400136753\n",
      "Current value of the loss function:  2.6675400136753\n",
      "Current value of the loss function:  2.6675400136752994\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424901420113\n",
      "Current value of the loss function:  3.733742445273157\n",
      "Current value of the loss function:  3.733742421445456\n",
      "Current value of the loss function:  3.7337424450588967\n",
      "Current value of the loss function:  3.733742445058898\n",
      "Current value of the loss function:  3.73374244538263\n",
      "Current value of the loss function:  3.733742490355559\n",
      "Current value of the loss function:  3.733742445058896\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.733742433826611\n",
      "Current value of the loss function:  3.733742468259292\n",
      "Current value of the loss function:  3.7337424450588967\n",
      "Current value of the loss function:  3.733742445058896\n",
      "Current value of the loss function:  3.733742440782232\n",
      "Current value of the loss function:  3.7337424372478147\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424450588963\n",
      "Current value of the loss function:  3.7337424413060747\n",
      "Current value of the loss function:  3.733742466347099\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424505227688\n",
      "Current value of the loss function:  3.7337424629973137\n",
      "Current value of the loss function:  3.7337424450588967\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424358061213\n",
      "Current value of the loss function:  3.733742484648825\n",
      "Current value of the loss function:  3.7337424450588963\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424423067636\n",
      "Current value of the loss function:  3.733742412609463\n",
      "Current value of the loss function:  3.7337424450588963\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.733742468181398\n",
      "Current value of the loss function:  3.7337424547431666\n",
      "Current value of the loss function:  3.733742445058895\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.733742445837307\n",
      "Current value of the loss function:  3.7337424695886403\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  3.7337424450588945\n",
      "Current value of the loss function:  3.7337424450588954\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.107734456553616\n",
      "Current value of the loss function:  2.107734464544384\n",
      "Current value of the loss function:  2.107734456520209\n",
      "Current value of the loss function:  2.1077344647718146\n",
      "Current value of the loss function:  2.1077344647718133\n",
      "Current value of the loss function:  2.107734464417477\n",
      "Current value of the loss function:  2.107734477896943\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.1077344647718133\n",
      "Current value of the loss function:  2.107734464596932\n",
      "Current value of the loss function:  2.107734476850344\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.107734465282162\n",
      "Current value of the loss function:  2.107734454327731\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.1077344704945618\n",
      "Current value of the loss function:  2.107734473061779\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.107734468187651\n",
      "Current value of the loss function:  2.107734453969188\n",
      "Current value of the loss function:  2.107734464771812\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.1077344666954807\n",
      "Current value of the loss function:  2.1077344704186496\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.1077344648804757\n",
      "Current value of the loss function:  2.1077344688844333\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.1077344647718137\n",
      "Current value of the loss function:  2.107734471067697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  2.1077344644631775\n",
      "Current value of the loss function:  2.107734464771814\n",
      "Current value of the loss function:  2.107734464771813\n",
      "Current value of the loss function:  2.107734465379143\n",
      "Current value of the loss function:  2.1077344659337793\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.1077344647718137\n",
      "Current value of the loss function:  2.1077344647718124\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.6769947625240063\n",
      "Current value of the loss function:  2.676994749059795\n",
      "Current value of the loss function:  2.6769947456759624\n",
      "Current value of the loss function:  2.676994749057559\n",
      "Current value of the loss function:  2.6769947490575627\n",
      "Current value of the loss function:  2.6769947500340137\n",
      "Current value of the loss function:  2.6769947207155713\n",
      "Current value of the loss function:  2.67699474905756\n",
      "Current value of the loss function:  2.67699474905756\n",
      "Current value of the loss function:  2.676994751398522\n",
      "Current value of the loss function:  2.6769947409683645\n",
      "Current value of the loss function:  2.67699474905756\n",
      "Current value of the loss function:  2.676994749057559\n",
      "Current value of the loss function:  2.6769947504663985\n",
      "Current value of the loss function:  2.67699476954514\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.676994749057559\n",
      "Current value of the loss function:  2.676994736279622\n",
      "Current value of the loss function:  2.6769947803081102\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.676994752920247\n",
      "Current value of the loss function:  2.6769947385129367\n",
      "Current value of the loss function:  2.676994749057559\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.676994744916013\n",
      "Current value of the loss function:  2.6769947348841887\n",
      "Current value of the loss function:  2.67699474905756\n",
      "Current value of the loss function:  2.6769947490575605\n",
      "Current value of the loss function:  2.676994747319677\n",
      "Current value of the loss function:  2.676994724281926\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.6769947535698875\n",
      "Current value of the loss function:  2.6769947305717547\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  2.676994750055547\n",
      "Current value of the loss function:  2.6769947513607435\n",
      "Current value of the loss function:  2.676994749057559\n",
      "Current value of the loss function:  2.6769947490575605\n",
      "Current value of the loss function:  2.6769947490575596\n",
      "Current value of the loss function:  1.9312310471132559\n",
      "Current value of the loss function:  1.9312310451544556\n",
      "Current value of the loss function:  1.9312310470359093\n",
      "Current value of the loss function:  1.9312310404618256\n",
      "Current value of the loss function:  1.9312310471132554\n",
      "Current value of the loss function:  1.931231047113258\n",
      "Current value of the loss function:  1.9312310470961296\n",
      "Current value of the loss function:  1.9312310457678596\n",
      "Current value of the loss function:  1.9312310471132559\n",
      "Current value of the loss function:  1.9312310471132592\n",
      "Current value of the loss function:  1.9312310467274159\n",
      "Current value of the loss function:  1.9312310523119451\n",
      "Current value of the loss function:  1.9312310471132574\n",
      "Current value of the loss function:  1.9312310471132574\n",
      "Current value of the loss function:  1.931231046774044\n",
      "Current value of the loss function:  1.9312310484489639\n",
      "Current value of the loss function:  1.9312310471132568\n",
      "Current value of the loss function:  1.9312310471132572\n",
      "Current value of the loss function:  1.931231047517638\n",
      "Current value of the loss function:  1.9312310623530624\n",
      "Current value of the loss function:  1.9312310471132565\n",
      "Current value of the loss function:  1.9312310471132572\n",
      "Current value of the loss function:  1.9312310507412553\n",
      "Current value of the loss function:  1.931231036604002\n",
      "Current value of the loss function:  1.931231047113255\n",
      "Current value of the loss function:  1.931231047113256\n",
      "Current value of the loss function:  1.9312310465653653\n",
      "Current value of the loss function:  1.9312310453302794\n",
      "Current value of the loss function:  1.9312310471132557\n",
      "Current value of the loss function:  1.9312310471132572\n",
      "Current value of the loss function:  1.9312310472268015\n",
      "Current value of the loss function:  1.9312310421322783\n",
      "Current value of the loss function:  1.9312310471132565\n",
      "Current value of the loss function:  1.9312310471132572\n",
      "Current value of the loss function:  1.9312310533022459\n",
      "Current value of the loss function:  1.9312310410811824\n",
      "Current value of the loss function:  1.9312310471132557\n",
      "Current value of the loss function:  1.9312310471132552\n",
      "Current value of the loss function:  1.9312310479522072\n",
      "Current value of the loss function:  1.9312310473223573\n",
      "Current value of the loss function:  1.9312310471132552\n",
      "Current value of the loss function:  1.9312310471132563\n",
      "Current value of the loss function:  1.9312310471132559\n",
      "Current value of the loss function:  1.7008366787206788\n",
      "Current value of the loss function:  1.7008366786828548\n",
      "Current value of the loss function:  1.7008366787184301\n",
      "Current value of the loss function:  1.7008366782084776\n",
      "Current value of the loss function:  1.7008366787206795\n",
      "Current value of the loss function:  1.7008366787206781\n",
      "Current value of the loss function:  1.7008366798411771\n",
      "Current value of the loss function:  1.7008366788600402\n",
      "Current value of the loss function:  1.7008366787206792\n",
      "Current value of the loss function:  1.7008366787206795\n",
      "Current value of the loss function:  1.7008366786026732\n",
      "Current value of the loss function:  1.7008366801362722\n",
      "Current value of the loss function:  1.7008366787206795\n",
      "Current value of the loss function:  1.7008366787206795\n",
      "Current value of the loss function:  1.700836677404576\n",
      "Current value of the loss function:  1.7008366818171874\n",
      "Current value of the loss function:  1.700836678720677\n",
      "Current value of the loss function:  1.70083667872068\n",
      "Current value of the loss function:  1.700836674328726\n",
      "Current value of the loss function:  1.7008366752379585\n",
      "Current value of the loss function:  1.7008366787206788\n",
      "Current value of the loss function:  1.700836678720679\n",
      "Current value of the loss function:  1.7008366840846991\n",
      "Current value of the loss function:  1.7008366687216365\n",
      "Current value of the loss function:  1.7008366787206792\n",
      "Current value of the loss function:  1.700836678720678\n",
      "Current value of the loss function:  1.700836678711296\n",
      "Current value of the loss function:  1.7008366809674802\n",
      "Current value of the loss function:  1.7008366787206783\n",
      "Current value of the loss function:  1.7008366787206783\n",
      "Current value of the loss function:  1.7008366789109766\n",
      "Current value of the loss function:  1.7008366706768503\n",
      "Current value of the loss function:  1.7008366787206766\n",
      "Current value of the loss function:  1.7008366787206781\n",
      "Current value of the loss function:  1.70083668353456\n",
      "Current value of the loss function:  1.7008366764428207\n",
      "Current value of the loss function:  1.700836678720679\n",
      "Current value of the loss function:  1.7008366787206792\n",
      "Current value of the loss function:  1.7008366797072874\n",
      "Current value of the loss function:  1.7008366781833417\n",
      "Current value of the loss function:  1.700836678720679\n",
      "Current value of the loss function:  1.7008366787206786\n",
      "Current value of the loss function:  1.7008366787206788\n",
      "Current value of the loss function:  1.594447136492985\n",
      "Current value of the loss function:  1.594447145662312\n",
      "Current value of the loss function:  1.5944471364872466\n",
      "Current value of the loss function:  1.594447142684486\n",
      "Current value of the loss function:  1.5944471364929844\n",
      "Current value of the loss function:  1.5944471364929833\n",
      "Current value of the loss function:  1.594447136939058\n",
      "Current value of the loss function:  1.5944471209581963\n",
      "Current value of the loss function:  1.5944471364929844\n",
      "Current value of the loss function:  1.5944471364929862\n",
      "Current value of the loss function:  1.5944471360952455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  1.594447139559338\n",
      "Current value of the loss function:  1.5944471364929855\n",
      "Current value of the loss function:  1.594447136492986\n",
      "Current value of the loss function:  1.5944471373859381\n",
      "Current value of the loss function:  1.5944471261917559\n",
      "Current value of the loss function:  1.5944471364929829\n",
      "Current value of the loss function:  1.5944471364929842\n",
      "Current value of the loss function:  1.5944471335733703\n",
      "Current value of the loss function:  1.594447122702025\n",
      "Current value of the loss function:  1.5944471364929849\n",
      "Current value of the loss function:  1.5944471364929846\n",
      "Current value of the loss function:  1.594447144777695\n",
      "Current value of the loss function:  1.5944471318325484\n",
      "Current value of the loss function:  1.5944471364929842\n",
      "Current value of the loss function:  1.5944471364929853\n",
      "Current value of the loss function:  1.5944471357441408\n",
      "Current value of the loss function:  1.5944471236122306\n",
      "Current value of the loss function:  1.5944471364929846\n",
      "Current value of the loss function:  1.5944471364929844\n",
      "Current value of the loss function:  1.5944471363891974\n",
      "Current value of the loss function:  1.5944471234469706\n",
      "Current value of the loss function:  1.5944471364929849\n",
      "Current value of the loss function:  1.5944471364929842\n",
      "Current value of the loss function:  1.5944471330738041\n",
      "Current value of the loss function:  1.594447150434511\n",
      "Current value of the loss function:  1.5944471364929833\n",
      "Current value of the loss function:  1.5944471364929849\n",
      "Current value of the loss function:  1.5944471364883617\n",
      "Current value of the loss function:  1.5944471287238586\n",
      "Current value of the loss function:  1.5944471364929846\n",
      "Current value of the loss function:  1.594447136492985\n",
      "Current value of the loss function:  1.594447136492985\n",
      "Current value of the loss function:  1.394420287739466\n",
      "Current value of the loss function:  1.3944202964275652\n",
      "Current value of the loss function:  1.3944202880257295\n",
      "Current value of the loss function:  1.3944202935528505\n",
      "Current value of the loss function:  1.394420287739465\n",
      "Current value of the loss function:  1.3944202877394642\n",
      "Current value of the loss function:  1.3944202868842812\n",
      "Current value of the loss function:  1.3944202760709565\n",
      "Current value of the loss function:  1.3944202877394658\n",
      "Current value of the loss function:  1.3944202877394658\n",
      "Current value of the loss function:  1.3944202874436002\n",
      "Current value of the loss function:  1.3944202914388506\n",
      "Current value of the loss function:  1.394420287739466\n",
      "Current value of the loss function:  1.3944202877394654\n",
      "Current value of the loss function:  1.3944202887490775\n",
      "Current value of the loss function:  1.394420280589144\n",
      "Current value of the loss function:  1.3944202877394654\n",
      "Current value of the loss function:  1.3944202877394656\n",
      "Current value of the loss function:  1.3944202859521055\n",
      "Current value of the loss function:  1.3944202744877956\n",
      "Current value of the loss function:  1.394420287739467\n",
      "Current value of the loss function:  1.3944202877394665\n",
      "Current value of the loss function:  1.394420294634137\n",
      "Current value of the loss function:  1.394420280316107\n",
      "Current value of the loss function:  1.3944202877394658\n",
      "Current value of the loss function:  1.3944202877394671\n",
      "Current value of the loss function:  1.3944202875004015\n",
      "Current value of the loss function:  1.3944202794695304\n",
      "Current value of the loss function:  1.3944202877394656\n",
      "Current value of the loss function:  1.3944202877394671\n",
      "Current value of the loss function:  1.3944202877666128\n",
      "Current value of the loss function:  1.3944202755712185\n",
      "Current value of the loss function:  1.3944202877394665\n",
      "Current value of the loss function:  1.394420287739466\n",
      "Current value of the loss function:  1.394420283794963\n",
      "Current value of the loss function:  1.394420299361753\n",
      "Current value of the loss function:  1.3944202877394676\n",
      "Current value of the loss function:  1.3944202877394667\n",
      "Current value of the loss function:  1.3944202873457332\n",
      "Current value of the loss function:  1.3944202826470642\n",
      "Current value of the loss function:  1.3944202877394656\n",
      "Current value of the loss function:  1.394420287739465\n",
      "Current value of the loss function:  1.394420287739466\n",
      "Current value of the loss function:  1.047539279521299\n",
      "Current value of the loss function:  1.0475392845721418\n",
      "Current value of the loss function:  1.0475392814303568\n",
      "Current value of the loss function:  1.047539283669522\n",
      "Current value of the loss function:  1.0475392795213008\n",
      "Current value of the loss function:  1.0475392795212977\n",
      "Current value of the loss function:  1.04753928027295\n",
      "Current value of the loss function:  1.0475392740354492\n",
      "Current value of the loss function:  1.0475392795212999\n",
      "Current value of the loss function:  1.0475392795212979\n",
      "Current value of the loss function:  1.04753927963261\n",
      "Current value of the loss function:  1.047539281373196\n",
      "Current value of the loss function:  1.047539279521298\n",
      "Current value of the loss function:  1.0475392795212979\n",
      "Current value of the loss function:  1.0475392809438602\n",
      "Current value of the loss function:  1.0475392748081271\n",
      "Current value of the loss function:  1.0475392795212988\n",
      "Current value of the loss function:  1.047539279521299\n",
      "Current value of the loss function:  1.0475392757614628\n",
      "Current value of the loss function:  1.0475392707947848\n",
      "Current value of the loss function:  1.047539279521301\n",
      "Current value of the loss function:  1.0475392795212997\n",
      "Current value of the loss function:  1.0475392813751618\n",
      "Current value of the loss function:  1.0475392719747734\n",
      "Current value of the loss function:  1.0475392795212999\n",
      "Current value of the loss function:  1.0475392795212992\n",
      "Current value of the loss function:  1.04753927970587\n",
      "Current value of the loss function:  1.047539275384211\n",
      "Current value of the loss function:  1.0475392795212999\n",
      "Current value of the loss function:  1.0475392795212985\n",
      "Current value of the loss function:  1.0475392798789138\n",
      "Current value of the loss function:  1.0475392725156176\n",
      "Current value of the loss function:  1.0475392795212994\n",
      "Current value of the loss function:  1.0475392795212994\n",
      "Current value of the loss function:  1.0475392766193827\n",
      "Current value of the loss function:  1.047539287000501\n",
      "Current value of the loss function:  1.0475392795212999\n",
      "Current value of the loss function:  1.0475392795212985\n",
      "Current value of the loss function:  1.0475392787480462\n",
      "Current value of the loss function:  1.0475392748135308\n",
      "Current value of the loss function:  1.0475392795212985\n",
      "Current value of the loss function:  1.0475392795212994\n",
      "Current value of the loss function:  1.047539279521299\n",
      "Current value of the loss function:  0.8812207458465343\n",
      "Current value of the loss function:  0.8812207416629146\n",
      "Current value of the loss function:  0.8812207465478425\n",
      "Current value of the loss function:  0.881220750518486\n",
      "Current value of the loss function:  0.881220745846534\n",
      "Current value of the loss function:  0.8812207458465328\n",
      "Current value of the loss function:  0.8812207388955319\n",
      "Current value of the loss function:  0.8812207534751588\n",
      "Current value of the loss function:  0.8812207458465343\n",
      "Current value of the loss function:  0.8812207458465317\n",
      "Current value of the loss function:  0.8812207460273779\n",
      "Current value of the loss function:  0.881220739975111\n",
      "Current value of the loss function:  0.8812207458465331\n",
      "Current value of the loss function:  0.8812207458465325\n",
      "Current value of the loss function:  0.8812207463724803\n",
      "Current value of the loss function:  0.8812207614479889\n",
      "Current value of the loss function:  0.8812207458465339\n",
      "Current value of the loss function:  0.8812207458465334\n",
      "Current value of the loss function:  0.8812207614933649\n",
      "Current value of the loss function:  0.8812207417307846\n",
      "Current value of the loss function:  0.8812207458465334\n",
      "Current value of the loss function:  0.8812207458465343\n",
      "Current value of the loss function:  0.8812207432613977\n",
      "Current value of the loss function:  0.8812207422754935\n",
      "Current value of the loss function:  0.8812207458465342\n",
      "Current value of the loss function:  0.8812207458465342\n",
      "Current value of the loss function:  0.8812207464186704\n",
      "Current value of the loss function:  0.8812207465049035\n",
      "Current value of the loss function:  0.8812207458465343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.8812207458465339\n",
      "Current value of the loss function:  0.8812207448113315\n",
      "Current value of the loss function:  0.8812207540853768\n",
      "Current value of the loss function:  0.8812207458465342\n",
      "Current value of the loss function:  0.8812207458465325\n",
      "Current value of the loss function:  0.8812207501587588\n",
      "Current value of the loss function:  0.881220745393763\n",
      "Current value of the loss function:  0.8812207458465339\n",
      "Current value of the loss function:  0.8812207458465343\n",
      "Current value of the loss function:  0.8812207458871048\n",
      "Current value of the loss function:  0.8812207473381355\n",
      "Current value of the loss function:  0.8812207458465348\n",
      "Current value of the loss function:  0.8812207458465338\n",
      "Current value of the loss function:  0.8812207458465343\n",
      "Current value of the loss function:  0.733628080688143\n",
      "Current value of the loss function:  0.7336280782644918\n",
      "Current value of the loss function:  0.7336280776788598\n",
      "Current value of the loss function:  0.7336280802566573\n",
      "Current value of the loss function:  0.7336280806881424\n",
      "Current value of the loss function:  0.7336280806881429\n",
      "Current value of the loss function:  0.7336280756674812\n",
      "Current value of the loss function:  0.7336280843127652\n",
      "Current value of the loss function:  0.7336280806881442\n",
      "Current value of the loss function:  0.7336280806881437\n",
      "Current value of the loss function:  0.7336280807956371\n",
      "Current value of the loss function:  0.733628078998454\n",
      "Current value of the loss function:  0.7336280806881443\n",
      "Current value of the loss function:  0.7336280806881428\n",
      "Current value of the loss function:  0.7336280822366115\n",
      "Current value of the loss function:  0.7336280894674011\n",
      "Current value of the loss function:  0.7336280806881417\n",
      "Current value of the loss function:  0.7336280806881419\n",
      "Current value of the loss function:  0.7336280775167456\n",
      "Current value of the loss function:  0.7336280828422465\n",
      "Current value of the loss function:  0.7336280806881432\n",
      "Current value of the loss function:  0.7336280806881428\n",
      "Current value of the loss function:  0.733628070548953\n",
      "Current value of the loss function:  0.7336280824807788\n",
      "Current value of the loss function:  0.7336280806881431\n",
      "Current value of the loss function:  0.733628080688143\n",
      "Current value of the loss function:  0.7336280809839353\n",
      "Current value of the loss function:  0.7336280805731099\n",
      "Current value of the loss function:  0.7336280806881437\n",
      "Current value of the loss function:  0.7336280806881439\n",
      "Current value of the loss function:  0.733628079605751\n",
      "Current value of the loss function:  0.7336280829764735\n",
      "Current value of the loss function:  0.7336280806881432\n",
      "Current value of the loss function:  0.7336280806881423\n",
      "Current value of the loss function:  0.733628081058521\n",
      "Current value of the loss function:  0.7336280746931562\n",
      "Current value of the loss function:  0.733628080688143\n",
      "Current value of the loss function:  0.7336280806881423\n",
      "Current value of the loss function:  0.7336280805450321\n",
      "Current value of the loss function:  0.7336280808157125\n",
      "Current value of the loss function:  0.7336280806881426\n",
      "Current value of the loss function:  0.7336280806881428\n",
      "Current value of the loss function:  0.733628080688143\n",
      "Current value of the loss function:  0.900247270585136\n",
      "Current value of the loss function:  0.9002472666096824\n",
      "Current value of the loss function:  0.9002472758969959\n",
      "Current value of the loss function:  0.9002472633628638\n",
      "Current value of the loss function:  0.9002472705851343\n",
      "Current value of the loss function:  0.9002472705851333\n",
      "Current value of the loss function:  0.9002472899487964\n",
      "Current value of the loss function:  0.9002472667994984\n",
      "Current value of the loss function:  0.9002472705851355\n",
      "Current value of the loss function:  0.9002472705851361\n",
      "Current value of the loss function:  0.9002472707252035\n",
      "Current value of the loss function:  0.9002472672170789\n",
      "Current value of the loss function:  0.900247270585133\n",
      "Current value of the loss function:  0.9002472705851369\n",
      "Current value of the loss function:  0.9002472727466979\n",
      "Current value of the loss function:  0.9002472740007873\n",
      "Current value of the loss function:  0.9002472705851345\n",
      "Current value of the loss function:  0.9002472705851352\n",
      "Current value of the loss function:  0.9002472668245034\n",
      "Current value of the loss function:  0.9002472731392624\n",
      "Current value of the loss function:  0.9002472705851358\n",
      "Current value of the loss function:  0.900247270585135\n",
      "Current value of the loss function:  0.900247284034653\n",
      "Current value of the loss function:  0.900247274760184\n",
      "Current value of the loss function:  0.9002472705851361\n",
      "Current value of the loss function:  0.9002472705851366\n",
      "Current value of the loss function:  0.9002472707752533\n",
      "Current value of the loss function:  0.9002472715910095\n",
      "Current value of the loss function:  0.9002472705851342\n",
      "Current value of the loss function:  0.9002472705851362\n",
      "Current value of the loss function:  0.900247270344785\n",
      "Current value of the loss function:  0.9002472723751158\n",
      "Current value of the loss function:  0.9002472705851357\n",
      "Current value of the loss function:  0.9002472705851361\n",
      "Current value of the loss function:  0.9002472666385767\n",
      "Current value of the loss function:  0.9002472654431121\n",
      "Current value of the loss function:  0.900247270585136\n",
      "Current value of the loss function:  0.9002472705851354\n",
      "Current value of the loss function:  0.9002472704303377\n",
      "Current value of the loss function:  0.9002472708913097\n",
      "Current value of the loss function:  0.9002472705851358\n",
      "Current value of the loss function:  0.9002472705851341\n",
      "Current value of the loss function:  0.900247270585136\n",
      "Current value of the loss function:  0.6855486246660103\n",
      "Current value of the loss function:  0.6855486216806975\n",
      "Current value of the loss function:  0.6855486244347471\n",
      "Current value of the loss function:  0.685548621907817\n",
      "Current value of the loss function:  0.6855486246660095\n",
      "Current value of the loss function:  0.6855486246660114\n",
      "Current value of the loss function:  0.6855486272544417\n",
      "Current value of the loss function:  0.6855486261333165\n",
      "Current value of the loss function:  0.6855486246660097\n",
      "Current value of the loss function:  0.6855486246660084\n",
      "Current value of the loss function:  0.6855486247867519\n",
      "Current value of the loss function:  0.6855486224576729\n",
      "Current value of the loss function:  0.6855486246660123\n",
      "Current value of the loss function:  0.685548624666009\n",
      "Current value of the loss function:  0.6855486264012066\n",
      "Current value of the loss function:  0.6855486315795156\n",
      "Current value of the loss function:  0.68554862466601\n",
      "Current value of the loss function:  0.6855486246660103\n",
      "Current value of the loss function:  0.6855486212787611\n",
      "Current value of the loss function:  0.6855486269525678\n",
      "Current value of the loss function:  0.6855486246660089\n",
      "Current value of the loss function:  0.68554862466601\n",
      "Current value of the loss function:  0.685548622180436\n",
      "Current value of the loss function:  0.6855486272142249\n",
      "Current value of the loss function:  0.6855486246660105\n",
      "Current value of the loss function:  0.6855486246660102\n",
      "Current value of the loss function:  0.6855486249231785\n",
      "Current value of the loss function:  0.6855486246818103\n",
      "Current value of the loss function:  0.6855486246660106\n",
      "Current value of the loss function:  0.6855486246660097\n",
      "Current value of the loss function:  0.6855486239251968\n",
      "Current value of the loss function:  0.6855486269498297\n",
      "Current value of the loss function:  0.6855486246660097\n",
      "Current value of the loss function:  0.6855486246660095\n",
      "Current value of the loss function:  0.6855486236335695\n",
      "Current value of the loss function:  0.6855486188904313\n",
      "Current value of the loss function:  0.6855486246660104\n",
      "Current value of the loss function:  0.6855486246660106\n",
      "Current value of the loss function:  0.6855486245179677\n",
      "Current value of the loss function:  0.6855486247637075\n",
      "Current value of the loss function:  0.6855486246660106\n",
      "Current value of the loss function:  0.6855486246660106\n",
      "Current value of the loss function:  0.6855486246660103\n",
      "Current value of the loss function:  0.665856830504773\n",
      "Current value of the loss function:  0.6658568270846691\n",
      "Current value of the loss function:  0.6658568313029877\n",
      "Current value of the loss function:  0.6658568265716781\n",
      "Current value of the loss function:  0.6658568305047722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.6658568305047732\n",
      "Current value of the loss function:  0.6658568280151689\n",
      "Current value of the loss function:  0.6658568230857271\n",
      "Current value of the loss function:  0.6658568305047736\n",
      "Current value of the loss function:  0.6658568305047706\n",
      "Current value of the loss function:  0.6658568306058915\n",
      "Current value of the loss function:  0.6658568285564072\n",
      "Current value of the loss function:  0.6658568305047731\n",
      "Current value of the loss function:  0.6658568305047723\n",
      "Current value of the loss function:  0.6658568329669596\n",
      "Current value of the loss function:  0.6658568296773265\n",
      "Current value of the loss function:  0.6658568305047727\n",
      "Current value of the loss function:  0.6658568305047732\n",
      "Current value of the loss function:  0.6658568328009242\n",
      "Current value of the loss function:  0.6658568318070582\n",
      "Current value of the loss function:  0.6658568305047731\n",
      "Current value of the loss function:  0.665856830504772\n",
      "Current value of the loss function:  0.6658568278494157\n",
      "Current value of the loss function:  0.6658568336012158\n",
      "Current value of the loss function:  0.6658568305047728\n",
      "Current value of the loss function:  0.6658568305047721\n",
      "Current value of the loss function:  0.665856830607712\n",
      "Current value of the loss function:  0.6658568253346409\n",
      "Current value of the loss function:  0.6658568305047721\n",
      "Current value of the loss function:  0.6658568305047725\n",
      "Current value of the loss function:  0.6658568303087571\n",
      "Current value of the loss function:  0.6658568307894857\n",
      "Current value of the loss function:  0.6658568305047712\n",
      "Current value of the loss function:  0.6658568305047708\n",
      "Current value of the loss function:  0.6658568261202025\n",
      "Current value of the loss function:  0.6658568307872504\n",
      "Current value of the loss function:  0.6658568305047734\n",
      "Current value of the loss function:  0.665856830504772\n",
      "Current value of the loss function:  0.665856830660609\n",
      "Current value of the loss function:  0.6658568275132352\n",
      "Current value of the loss function:  0.6658568305047735\n",
      "Current value of the loss function:  0.6658568305047731\n",
      "Current value of the loss function:  0.665856830504773\n",
      "Current value of the loss function:  0.6432939613778227\n",
      "Current value of the loss function:  0.6432939596676283\n",
      "Current value of the loss function:  0.6432939575230163\n",
      "Current value of the loss function:  0.6432939586341021\n",
      "Current value of the loss function:  0.643293961377824\n",
      "Current value of the loss function:  0.6432939613778248\n",
      "Current value of the loss function:  0.6432939592652955\n",
      "Current value of the loss function:  0.6432939552737956\n",
      "Current value of the loss function:  0.6432939613778226\n",
      "Current value of the loss function:  0.6432939613778204\n",
      "Current value of the loss function:  0.6432939614442177\n",
      "Current value of the loss function:  0.6432939610436855\n",
      "Current value of the loss function:  0.6432939613778216\n",
      "Current value of the loss function:  0.6432939613778229\n",
      "Current value of the loss function:  0.6432939639240297\n",
      "Current value of the loss function:  0.6432939620976794\n",
      "Current value of the loss function:  0.6432939613778226\n",
      "Current value of the loss function:  0.6432939613778229\n",
      "Current value of the loss function:  0.6432939628043662\n",
      "Current value of the loss function:  0.6432939623848177\n",
      "Current value of the loss function:  0.6432939613778244\n",
      "Current value of the loss function:  0.6432939613778237\n",
      "Current value of the loss function:  0.6432939619568263\n",
      "Current value of the loss function:  0.6432939648416907\n",
      "Current value of the loss function:  0.643293961377823\n",
      "Current value of the loss function:  0.6432939613778222\n",
      "Current value of the loss function:  0.6432939614875168\n",
      "Current value of the loss function:  0.6432939559754022\n",
      "Current value of the loss function:  0.6432939613778217\n",
      "Current value of the loss function:  0.6432939613778212\n",
      "Current value of the loss function:  0.6432939612740732\n",
      "Current value of the loss function:  0.6432939616322781\n",
      "Current value of the loss function:  0.6432939613778238\n",
      "Current value of the loss function:  0.6432939613778216\n",
      "Current value of the loss function:  0.643293959355338\n",
      "Current value of the loss function:  0.643293961833703\n",
      "Current value of the loss function:  0.6432939613778218\n",
      "Current value of the loss function:  0.643293961377822\n",
      "Current value of the loss function:  0.643293961467094\n",
      "Current value of the loss function:  0.643293959012442\n",
      "Current value of the loss function:  0.6432939613778224\n",
      "Current value of the loss function:  0.6432939613778234\n",
      "Current value of the loss function:  0.6432939613778227\n",
      "Current value of the loss function:  0.6087975113860474\n",
      "Current value of the loss function:  0.608797511297317\n",
      "Current value of the loss function:  0.6087975086913373\n",
      "Current value of the loss function:  0.6087975098428559\n",
      "Current value of the loss function:  0.6087975113860499\n",
      "Current value of the loss function:  0.608797511386048\n",
      "Current value of the loss function:  0.6087975120305144\n",
      "Current value of the loss function:  0.6087975076381779\n",
      "Current value of the loss function:  0.6087975113860479\n",
      "Current value of the loss function:  0.608797511386047\n",
      "Current value of the loss function:  0.6087975114471056\n",
      "Current value of the loss function:  0.6087975118802873\n",
      "Current value of the loss function:  0.6087975113860461\n",
      "Current value of the loss function:  0.6087975113860477\n",
      "Current value of the loss function:  0.6087975138404702\n",
      "Current value of the loss function:  0.6087975164262843\n",
      "Current value of the loss function:  0.6087975113860471\n",
      "Current value of the loss function:  0.6087975113860473\n",
      "Current value of the loss function:  0.6087975121505943\n",
      "Current value of the loss function:  0.6087975118033966\n",
      "Current value of the loss function:  0.6087975113860469\n",
      "Current value of the loss function:  0.6087975113860474\n",
      "Current value of the loss function:  0.6087975104368835\n",
      "Current value of the loss function:  0.6087975159011804\n",
      "Current value of the loss function:  0.6087975113860475\n",
      "Current value of the loss function:  0.6087975113860478\n",
      "Current value of the loss function:  0.6087975114278164\n",
      "Current value of the loss function:  0.6087975064768425\n",
      "Current value of the loss function:  0.6087975113860469\n",
      "Current value of the loss function:  0.6087975113860485\n",
      "Current value of the loss function:  0.6087975112642636\n",
      "Current value of the loss function:  0.6087975119891317\n",
      "Current value of the loss function:  0.6087975113860472\n",
      "Current value of the loss function:  0.6087975113860488\n",
      "Current value of the loss function:  0.6087975100360645\n",
      "Current value of the loss function:  0.6087975123279878\n",
      "Current value of the loss function:  0.6087975113860473\n",
      "Current value of the loss function:  0.6087975113860475\n",
      "Current value of the loss function:  0.6087975112589806\n",
      "Current value of the loss function:  0.6087975101415929\n",
      "Current value of the loss function:  0.6087975113860489\n",
      "Current value of the loss function:  0.6087975113860484\n",
      "Current value of the loss function:  0.6087975113860474\n",
      "Current value of the loss function:  0.565966591680869\n",
      "Current value of the loss function:  0.5659665901121093\n",
      "Current value of the loss function:  0.5659665926063424\n",
      "Current value of the loss function:  0.5659665893009466\n",
      "Current value of the loss function:  0.5659665916808698\n",
      "Current value of the loss function:  0.5659665916808673\n",
      "Current value of the loss function:  0.5659665912029589\n",
      "Current value of the loss function:  0.5659665897502502\n",
      "Current value of the loss function:  0.5659665916808686\n",
      "Current value of the loss function:  0.5659665916808689\n",
      "Current value of the loss function:  0.5659665917645434\n",
      "Current value of the loss function:  0.5659665901291099\n",
      "Current value of the loss function:  0.5659665916808704\n",
      "Current value of the loss function:  0.5659665916808692\n",
      "Current value of the loss function:  0.5659665937707189\n",
      "Current value of the loss function:  0.5659665992587796\n",
      "Current value of the loss function:  0.5659665916808692\n",
      "Current value of the loss function:  0.5659665916808709\n",
      "Current value of the loss function:  0.5659665891920608\n",
      "Current value of the loss function:  0.5659665930543181\n",
      "Current value of the loss function:  0.5659665916808687\n",
      "Current value of the loss function:  0.5659665916808682\n",
      "Current value of the loss function:  0.565966593133252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.5659665986706305\n",
      "Current value of the loss function:  0.5659665916808707\n",
      "Current value of the loss function:  0.5659665916808695\n",
      "Current value of the loss function:  0.5659665916807355\n",
      "Current value of the loss function:  0.5659665867389536\n",
      "Current value of the loss function:  0.5659665916808686\n",
      "Current value of the loss function:  0.565966591680869\n",
      "Current value of the loss function:  0.565966591597311\n",
      "Current value of the loss function:  0.5659665943989856\n",
      "Current value of the loss function:  0.5659665916808682\n",
      "Current value of the loss function:  0.5659665916808697\n",
      "Current value of the loss function:  0.5659665938496796\n",
      "Current value of the loss function:  0.565966592438356\n",
      "Current value of the loss function:  0.5659665916808688\n",
      "Current value of the loss function:  0.5659665916808702\n",
      "Current value of the loss function:  0.565966591942274\n",
      "Current value of the loss function:  0.5659665898451848\n",
      "Current value of the loss function:  0.5659665916808704\n",
      "Current value of the loss function:  0.5659665916808688\n",
      "Current value of the loss function:  0.565966591680869\n",
      "Current value of the loss function:  0.5309321968457148\n",
      "Current value of the loss function:  0.5309321963577891\n",
      "Current value of the loss function:  0.5309321962234188\n",
      "Current value of the loss function:  0.5309321943040294\n",
      "Current value of the loss function:  0.5309321968457142\n",
      "Current value of the loss function:  0.5309321968457151\n",
      "Current value of the loss function:  0.530932201166417\n",
      "Current value of the loss function:  0.5309321951207359\n",
      "Current value of the loss function:  0.530932196845715\n",
      "Current value of the loss function:  0.5309321968457135\n",
      "Current value of the loss function:  0.5309321969742162\n",
      "Current value of the loss function:  0.5309321959763423\n",
      "Current value of the loss function:  0.5309321968457134\n",
      "Current value of the loss function:  0.5309321968457117\n",
      "Current value of the loss function:  0.5309321961705261\n",
      "Current value of the loss function:  0.5309322046582399\n",
      "Current value of the loss function:  0.5309321968457128\n",
      "Current value of the loss function:  0.5309321968457148\n",
      "Current value of the loss function:  0.5309321965816348\n",
      "Current value of the loss function:  0.5309321987648578\n",
      "Current value of the loss function:  0.530932196845715\n",
      "Current value of the loss function:  0.530932196845713\n",
      "Current value of the loss function:  0.530932194732717\n",
      "Current value of the loss function:  0.5309322071474333\n",
      "Current value of the loss function:  0.5309321968457152\n",
      "Current value of the loss function:  0.5309321968457152\n",
      "Current value of the loss function:  0.5309321968954794\n",
      "Current value of the loss function:  0.5309321914852381\n",
      "Current value of the loss function:  0.530932196845714\n",
      "Current value of the loss function:  0.5309321968457141\n",
      "Current value of the loss function:  0.530932196940078\n",
      "Current value of the loss function:  0.5309321983645156\n",
      "Current value of the loss function:  0.5309321968457144\n",
      "Current value of the loss function:  0.5309321968457137\n",
      "Current value of the loss function:  0.5309322013791702\n",
      "Current value of the loss function:  0.5309321961531903\n",
      "Current value of the loss function:  0.5309321968457161\n",
      "Current value of the loss function:  0.5309321968457141\n",
      "Current value of the loss function:  0.5309321973301679\n",
      "Current value of the loss function:  0.5309321960404872\n",
      "Current value of the loss function:  0.5309321968457149\n",
      "Current value of the loss function:  0.5309321968457161\n",
      "Current value of the loss function:  0.5309321968457148\n",
      "Current value of the loss function:  0.474155404348826\n",
      "Current value of the loss function:  0.47415540379507803\n",
      "Current value of the loss function:  0.4741554049131358\n",
      "Current value of the loss function:  0.47415540458457395\n",
      "Current value of the loss function:  0.4741554043488253\n",
      "Current value of the loss function:  0.4741554043488249\n",
      "Current value of the loss function:  0.4741554069699926\n",
      "Current value of the loss function:  0.4741554032124321\n",
      "Current value of the loss function:  0.47415540434882775\n",
      "Current value of the loss function:  0.47415540434882464\n",
      "Current value of the loss function:  0.47415540446557247\n",
      "Current value of the loss function:  0.4741554024963733\n",
      "Current value of the loss function:  0.4741554043488253\n",
      "Current value of the loss function:  0.4741554043488242\n",
      "Current value of the loss function:  0.4741554034151004\n",
      "Current value of the loss function:  0.474155413896772\n",
      "Current value of the loss function:  0.47415540434882725\n",
      "Current value of the loss function:  0.47415540434882486\n",
      "Current value of the loss function:  0.47415540233367914\n",
      "Current value of the loss function:  0.47415540449060783\n",
      "Current value of the loss function:  0.4741554043488253\n",
      "Current value of the loss function:  0.47415540434882486\n",
      "Current value of the loss function:  0.47415540314174975\n",
      "Current value of the loss function:  0.47415541132744154\n",
      "Current value of the loss function:  0.47415540434882464\n",
      "Current value of the loss function:  0.4741554043488265\n",
      "Current value of the loss function:  0.47415540424823305\n",
      "Current value of the loss function:  0.47415539989862576\n",
      "Current value of the loss function:  0.474155404348826\n",
      "Current value of the loss function:  0.47415540434882625\n",
      "Current value of the loss function:  0.4741554045668754\n",
      "Current value of the loss function:  0.4741554056097443\n",
      "Current value of the loss function:  0.4741554043488259\n",
      "Current value of the loss function:  0.4741554043488248\n",
      "Current value of the loss function:  0.4741554060795687\n",
      "Current value of the loss function:  0.474155405266114\n",
      "Current value of the loss function:  0.4741554043488245\n",
      "Current value of the loss function:  0.47415540434882547\n",
      "Current value of the loss function:  0.4741554040753426\n",
      "Current value of the loss function:  0.474155404072046\n",
      "Current value of the loss function:  0.4741554043488262\n",
      "Current value of the loss function:  0.4741554043488262\n",
      "Current value of the loss function:  0.474155404348826\n",
      "Current value of the loss function:  0.3883782124861019\n",
      "Current value of the loss function:  0.3883782142639499\n",
      "Current value of the loss function:  0.38837821591512617\n",
      "Current value of the loss function:  0.38837821467672506\n",
      "Current value of the loss function:  0.3883782124861057\n",
      "Current value of the loss function:  0.38837821248610255\n",
      "Current value of the loss function:  0.3883782136616824\n",
      "Current value of the loss function:  0.38837821048368243\n",
      "Current value of the loss function:  0.3883782124861012\n",
      "Current value of the loss function:  0.38837821248610155\n",
      "Current value of the loss function:  0.38837821255354876\n",
      "Current value of the loss function:  0.3883782133275904\n",
      "Current value of the loss function:  0.3883782124861016\n",
      "Current value of the loss function:  0.38837821248610027\n",
      "Current value of the loss function:  0.3883782133523381\n",
      "Current value of the loss function:  0.38837822056075033\n",
      "Current value of the loss function:  0.3883782124861007\n",
      "Current value of the loss function:  0.38837821248609994\n",
      "Current value of the loss function:  0.3883782114908006\n",
      "Current value of the loss function:  0.3883782119900751\n",
      "Current value of the loss function:  0.3883782124861017\n",
      "Current value of the loss function:  0.38837821248610005\n",
      "Current value of the loss function:  0.3883782111732362\n",
      "Current value of the loss function:  0.3883782167227982\n",
      "Current value of the loss function:  0.3883782124861022\n",
      "Current value of the loss function:  0.3883782124861022\n",
      "Current value of the loss function:  0.3883782122017724\n",
      "Current value of the loss function:  0.3883782087560008\n",
      "Current value of the loss function:  0.3883782124861005\n",
      "Current value of the loss function:  0.3883782124861012\n",
      "Current value of the loss function:  0.3883782126656972\n",
      "Current value of the loss function:  0.3883782087751601\n",
      "Current value of the loss function:  0.38837821248610055\n",
      "Current value of the loss function:  0.3883782124861017\n",
      "Current value of the loss function:  0.3883782142664451\n",
      "Current value of the loss function:  0.38837821240688186\n",
      "Current value of the loss function:  0.38837821248609994\n",
      "Current value of the loss function:  0.38837821248610055\n",
      "Current value of the loss function:  0.38837821352257657\n",
      "Current value of the loss function:  0.38837821168670733\n",
      "Current value of the loss function:  0.3883782124861012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.38837821248610105\n",
      "Current value of the loss function:  0.3883782124861019\n",
      "Current value of the loss function:  0.27090454843570466\n",
      "Current value of the loss function:  0.27090454671529274\n",
      "Current value of the loss function:  0.27090455044314965\n",
      "Current value of the loss function:  0.2709045519385043\n",
      "Current value of the loss function:  0.27090454843570294\n",
      "Current value of the loss function:  0.2709045484357045\n",
      "Current value of the loss function:  0.2709045491422407\n",
      "Current value of the loss function:  0.2709045424645234\n",
      "Current value of the loss function:  0.2709045484357054\n",
      "Current value of the loss function:  0.27090454843570433\n",
      "Current value of the loss function:  0.27090454847162126\n",
      "Current value of the loss function:  0.2709045467257802\n",
      "Current value of the loss function:  0.2709045484357044\n",
      "Current value of the loss function:  0.2709045484357042\n",
      "Current value of the loss function:  0.27090454942257614\n",
      "Current value of the loss function:  0.2709045526129388\n",
      "Current value of the loss function:  0.27090454843570383\n",
      "Current value of the loss function:  0.2709045484357034\n",
      "Current value of the loss function:  0.2709045459656112\n",
      "Current value of the loss function:  0.27090454622178706\n",
      "Current value of the loss function:  0.27090454843570416\n",
      "Current value of the loss function:  0.2709045484357045\n",
      "Current value of the loss function:  0.27090454631994487\n",
      "Current value of the loss function:  0.2709045460604441\n",
      "Current value of the loss function:  0.27090454843570366\n",
      "Current value of the loss function:  0.2709045484357049\n",
      "Current value of the loss function:  0.27090454708338135\n",
      "Current value of the loss function:  0.27090454592361946\n",
      "Current value of the loss function:  0.27090454843570466\n",
      "Current value of the loss function:  0.27090454843570416\n",
      "Current value of the loss function:  0.27090454843202044\n",
      "Current value of the loss function:  0.270904547372228\n",
      "Current value of the loss function:  0.2709045484357054\n",
      "Current value of the loss function:  0.27090454843570555\n",
      "Current value of the loss function:  0.2709045508304392\n",
      "Current value of the loss function:  0.2709045524404252\n",
      "Current value of the loss function:  0.27090454843570416\n",
      "Current value of the loss function:  0.2709045484357047\n",
      "Current value of the loss function:  0.27090454765951494\n",
      "Current value of the loss function:  0.27090454590373714\n",
      "Current value of the loss function:  0.27090454843570483\n",
      "Current value of the loss function:  0.2709045484357059\n",
      "Current value of the loss function:  0.27090454843570466\n",
      "Current value of the loss function:  0.5911370445158547\n",
      "Current value of the loss function:  0.5911370595558111\n",
      "Current value of the loss function:  0.5911370490894053\n",
      "Current value of the loss function:  0.5911370452258908\n",
      "Current value of the loss function:  0.5911370445158554\n",
      "Current value of the loss function:  0.5911370445158547\n",
      "Current value of the loss function:  0.5911370400916603\n",
      "Current value of the loss function:  0.5911370395307649\n",
      "Current value of the loss function:  0.591137044515854\n",
      "Current value of the loss function:  0.5911370445158544\n",
      "Current value of the loss function:  0.5911370428497258\n",
      "Current value of the loss function:  0.5911370487719392\n",
      "Current value of the loss function:  0.591137044515855\n",
      "Current value of the loss function:  0.5911370445158548\n",
      "Current value of the loss function:  0.591137027234901\n",
      "Current value of the loss function:  0.5911370400304596\n",
      "Current value of the loss function:  0.591137044515855\n",
      "Current value of the loss function:  0.5911370445158539\n",
      "Current value of the loss function:  0.5911370439686812\n",
      "Current value of the loss function:  0.5911370412223824\n",
      "Current value of the loss function:  0.5911370445158535\n",
      "Current value of the loss function:  0.5911370445158562\n",
      "Current value of the loss function:  0.5911370496177571\n",
      "Current value of the loss function:  0.5911370488335873\n",
      "Current value of the loss function:  0.5911370445158547\n",
      "Current value of the loss function:  0.5911370445158549\n",
      "Current value of the loss function:  0.5911370407070755\n",
      "Current value of the loss function:  0.5911370508983496\n",
      "Current value of the loss function:  0.5911370445158537\n",
      "Current value of the loss function:  0.5911370445158548\n",
      "Current value of the loss function:  0.5911370458673502\n",
      "Current value of the loss function:  0.5911370673525184\n",
      "Current value of the loss function:  0.591137044515855\n",
      "Current value of the loss function:  0.5911370445158539\n",
      "Current value of the loss function:  0.5911370404605735\n",
      "Current value of the loss function:  0.5911370418129971\n",
      "Current value of the loss function:  0.5911370445158555\n",
      "Current value of the loss function:  0.5911370445158526\n",
      "Current value of the loss function:  0.5911370459336216\n",
      "Current value of the loss function:  0.5911370442786039\n",
      "Current value of the loss function:  0.5911370445158541\n",
      "Current value of the loss function:  0.5911370445158544\n",
      "Current value of the loss function:  0.5911370445158547\n",
      "Current value of the loss function:  0.24560334792814256\n",
      "Current value of the loss function:  0.24560334916680224\n",
      "Current value of the loss function:  0.2456033505042493\n",
      "Current value of the loss function:  0.2456033511681117\n",
      "Current value of the loss function:  0.24560334792814384\n",
      "Current value of the loss function:  0.24560334792814112\n",
      "Current value of the loss function:  0.2456033474575092\n",
      "Current value of the loss function:  0.24560334223328797\n",
      "Current value of the loss function:  0.2456033479281432\n",
      "Current value of the loss function:  0.24560334792814392\n",
      "Current value of the loss function:  0.2456033479292789\n",
      "Current value of the loss function:  0.24560334877355136\n",
      "Current value of the loss function:  0.24560334792814276\n",
      "Current value of the loss function:  0.2456033479281426\n",
      "Current value of the loss function:  0.24560334650694557\n",
      "Current value of the loss function:  0.24560335087425267\n",
      "Current value of the loss function:  0.24560334792814292\n",
      "Current value of the loss function:  0.2456033479281435\n",
      "Current value of the loss function:  0.24560334587870844\n",
      "Current value of the loss function:  0.2456033453835891\n",
      "Current value of the loss function:  0.245603347928144\n",
      "Current value of the loss function:  0.24560334792814292\n",
      "Current value of the loss function:  0.2456033473823273\n",
      "Current value of the loss function:  0.2456033468559392\n",
      "Current value of the loss function:  0.24560334792814126\n",
      "Current value of the loss function:  0.2456033479281432\n",
      "Current value of the loss function:  0.24560334613252538\n",
      "Current value of the loss function:  0.24560334663035605\n",
      "Current value of the loss function:  0.24560334792814223\n",
      "Current value of the loss function:  0.24560334792814226\n",
      "Current value of the loss function:  0.24560334805767978\n",
      "Current value of the loss function:  0.24560334941175846\n",
      "Current value of the loss function:  0.2456033479281421\n",
      "Current value of the loss function:  0.24560334792814226\n",
      "Current value of the loss function:  0.24560334891781993\n",
      "Current value of the loss function:  0.2456033504427723\n",
      "Current value of the loss function:  0.2456033479281435\n",
      "Current value of the loss function:  0.24560334792814176\n",
      "Current value of the loss function:  0.2456033475906061\n",
      "Current value of the loss function:  0.24560334570833892\n",
      "Current value of the loss function:  0.24560334792814126\n",
      "Current value of the loss function:  0.24560334792814079\n",
      "Current value of the loss function:  0.24560334792814256\n",
      "Current value of the loss function:  0.21145894244828678\n",
      "Current value of the loss function:  0.21145894297027454\n",
      "Current value of the loss function:  0.21145894230983775\n",
      "Current value of the loss function:  0.21145894466398527\n",
      "Current value of the loss function:  0.21145894244828692\n",
      "Current value of the loss function:  0.21145894244828628\n",
      "Current value of the loss function:  0.21145894201928933\n",
      "Current value of the loss function:  0.2114589382389936\n",
      "Current value of the loss function:  0.21145894244828614\n",
      "Current value of the loss function:  0.21145894244828595\n",
      "Current value of the loss function:  0.21145894255057932\n",
      "Current value of the loss function:  0.2114589412748871\n",
      "Current value of the loss function:  0.21145894244828595\n",
      "Current value of the loss function:  0.21145894244828775\n",
      "Current value of the loss function:  0.21145894251676525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.21145894331774082\n",
      "Current value of the loss function:  0.21145894244828728\n",
      "Current value of the loss function:  0.21145894244828561\n",
      "Current value of the loss function:  0.21145894171314178\n",
      "Current value of the loss function:  0.21145894024185866\n",
      "Current value of the loss function:  0.21145894244828595\n",
      "Current value of the loss function:  0.2114589424482879\n",
      "Current value of the loss function:  0.21145894313750838\n",
      "Current value of the loss function:  0.2114589417289215\n",
      "Current value of the loss function:  0.2114589424482866\n",
      "Current value of the loss function:  0.21145894244828775\n",
      "Current value of the loss function:  0.21145894096133716\n",
      "Current value of the loss function:  0.21145894103014906\n",
      "Current value of the loss function:  0.21145894244828595\n",
      "Current value of the loss function:  0.21145894244828628\n",
      "Current value of the loss function:  0.21145894250718167\n",
      "Current value of the loss function:  0.21145894372474436\n",
      "Current value of the loss function:  0.2114589424482871\n",
      "Current value of the loss function:  0.21145894244828695\n",
      "Current value of the loss function:  0.21145894155830983\n",
      "Current value of the loss function:  0.21145894342510946\n",
      "Current value of the loss function:  0.21145894244828708\n",
      "Current value of the loss function:  0.21145894244828545\n",
      "Current value of the loss function:  0.21145894263605006\n",
      "Current value of the loss function:  0.2114589398024402\n",
      "Current value of the loss function:  0.21145894244828645\n",
      "Current value of the loss function:  0.2114589424482866\n",
      "Current value of the loss function:  0.21145894244828678\n",
      "Current value of the loss function:  0.18860653178892584\n",
      "Current value of the loss function:  0.18860653250144124\n",
      "Current value of the loss function:  0.18860653099675562\n",
      "Current value of the loss function:  0.18860653210672826\n",
      "Current value of the loss function:  0.18860653178892572\n",
      "Current value of the loss function:  0.18860653178892492\n",
      "Current value of the loss function:  0.18860653147406478\n",
      "Current value of the loss function:  0.1886065310387234\n",
      "Current value of the loss function:  0.18860653178892733\n",
      "Current value of the loss function:  0.18860653178892572\n",
      "Current value of the loss function:  0.18860653204991945\n",
      "Current value of the loss function:  0.18860652873567205\n",
      "Current value of the loss function:  0.1886065317889265\n",
      "Current value of the loss function:  0.18860653178892617\n",
      "Current value of the loss function:  0.18860653051210416\n",
      "Current value of the loss function:  0.18860653195942514\n",
      "Current value of the loss function:  0.1886065317889262\n",
      "Current value of the loss function:  0.18860653178892733\n",
      "Current value of the loss function:  0.18860653195458904\n",
      "Current value of the loss function:  0.18860653035234243\n",
      "Current value of the loss function:  0.18860653178892683\n",
      "Current value of the loss function:  0.18860653178892575\n",
      "Current value of the loss function:  0.18860653177815428\n",
      "Current value of the loss function:  0.1886065330241347\n",
      "Current value of the loss function:  0.18860653178892633\n",
      "Current value of the loss function:  0.18860653178892683\n",
      "Current value of the loss function:  0.18860653051687168\n",
      "Current value of the loss function:  0.18860653077477696\n",
      "Current value of the loss function:  0.18860653178892586\n",
      "Current value of the loss function:  0.18860653178892556\n",
      "Current value of the loss function:  0.18860653170069405\n",
      "Current value of the loss function:  0.18860653213152884\n",
      "Current value of the loss function:  0.1886065317889259\n",
      "Current value of the loss function:  0.18860653178892442\n",
      "Current value of the loss function:  0.18860653182046472\n",
      "Current value of the loss function:  0.18860653095135302\n",
      "Current value of the loss function:  0.18860653178892617\n",
      "Current value of the loss function:  0.1886065317889262\n",
      "Current value of the loss function:  0.18860653073054695\n",
      "Current value of the loss function:  0.1886065306932944\n",
      "Current value of the loss function:  0.18860653178892522\n",
      "Current value of the loss function:  0.18860653178892653\n",
      "Current value of the loss function:  0.18860653178892584\n",
      "Current value of the loss function:  0.18824884328664485\n",
      "Current value of the loss function:  0.18824884516385304\n",
      "Current value of the loss function:  0.18824884136506065\n",
      "Current value of the loss function:  0.1882488412838868\n",
      "Current value of the loss function:  0.18824884328664518\n",
      "Current value of the loss function:  0.1882488432866419\n",
      "Current value of the loss function:  0.1882488435201291\n",
      "Current value of the loss function:  0.18824884521759563\n",
      "Current value of the loss function:  0.18824884328664532\n",
      "Current value of the loss function:  0.1882488432866453\n",
      "Current value of the loss function:  0.1882488434663632\n",
      "Current value of the loss function:  0.18824884194686442\n",
      "Current value of the loss function:  0.18824884328664465\n",
      "Current value of the loss function:  0.18824884328664307\n",
      "Current value of the loss function:  0.18824884531708772\n",
      "Current value of the loss function:  0.1882488439152171\n",
      "Current value of the loss function:  0.18824884328664307\n",
      "Current value of the loss function:  0.188248843286644\n",
      "Current value of the loss function:  0.18824884296177444\n",
      "Current value of the loss function:  0.1882488436113468\n",
      "Current value of the loss function:  0.18824884328664468\n",
      "Current value of the loss function:  0.18824884328664335\n",
      "Current value of the loss function:  0.18824884267607103\n",
      "Current value of the loss function:  0.188248844989476\n",
      "Current value of the loss function:  0.18824884328664435\n",
      "Current value of the loss function:  0.18824884328664498\n",
      "Current value of the loss function:  0.18824884253476415\n",
      "Current value of the loss function:  0.18824884422361735\n",
      "Current value of the loss function:  0.18824884328664301\n",
      "Current value of the loss function:  0.18824884328664418\n",
      "Current value of the loss function:  0.18824884323822194\n",
      "Current value of the loss function:  0.18824884620513405\n",
      "Current value of the loss function:  0.18824884328664404\n",
      "Current value of the loss function:  0.18824884328664418\n",
      "Current value of the loss function:  0.1882488432901255\n",
      "Current value of the loss function:  0.1882488420420365\n",
      "Current value of the loss function:  0.18824884328664515\n",
      "Current value of the loss function:  0.18824884328664512\n",
      "Current value of the loss function:  0.18824884915461323\n",
      "Current value of the loss function:  0.18824884455814045\n",
      "Current value of the loss function:  0.18824884328664532\n",
      "Current value of the loss function:  0.18824884328664448\n",
      "Current value of the loss function:  0.18824884328664485\n",
      "Current value of the loss function:  0.17900220253650395\n",
      "Current value of the loss function:  0.17900220380916984\n",
      "Current value of the loss function:  0.17900220119575735\n",
      "Current value of the loss function:  0.17900220171643477\n",
      "Current value of the loss function:  0.17900220253650478\n",
      "Current value of the loss function:  0.17900220253650265\n",
      "Current value of the loss function:  0.1790022024944137\n",
      "Current value of the loss function:  0.17900220310295278\n",
      "Current value of the loss function:  0.17900220253650545\n",
      "Current value of the loss function:  0.17900220253650154\n",
      "Current value of the loss function:  0.17900220276259046\n",
      "Current value of the loss function:  0.17900220031588826\n",
      "Current value of the loss function:  0.17900220253650428\n",
      "Current value of the loss function:  0.1790022025365033\n",
      "Current value of the loss function:  0.17900220274779383\n",
      "Current value of the loss function:  0.17900220297939562\n",
      "Current value of the loss function:  0.17900220253650315\n",
      "Current value of the loss function:  0.1790022025365041\n",
      "Current value of the loss function:  0.1790022024630916\n",
      "Current value of the loss function:  0.17900220195753702\n",
      "Current value of the loss function:  0.179002202536503\n",
      "Current value of the loss function:  0.17900220253650345\n",
      "Current value of the loss function:  0.1790022022334872\n",
      "Current value of the loss function:  0.17900220399794697\n",
      "Current value of the loss function:  0.17900220253650428\n",
      "Current value of the loss function:  0.1790022025365056\n",
      "Current value of the loss function:  0.17900220146907117\n",
      "Current value of the loss function:  0.17900220242600143\n",
      "Current value of the loss function:  0.17900220253650656\n",
      "Current value of the loss function:  0.17900220253650473\n",
      "Current value of the loss function:  0.17900220246379778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.17900220405886708\n",
      "Current value of the loss function:  0.1790022025365033\n",
      "Current value of the loss function:  0.1790022025365025\n",
      "Current value of the loss function:  0.1790022025549486\n",
      "Current value of the loss function:  0.17900220148552107\n",
      "Current value of the loss function:  0.17900220253650329\n",
      "Current value of the loss function:  0.17900220253650345\n",
      "Current value of the loss function:  0.17900220473355447\n",
      "Current value of the loss function:  0.17900220255988397\n",
      "Current value of the loss function:  0.17900220253650423\n",
      "Current value of the loss function:  0.1790022025365054\n",
      "Current value of the loss function:  0.17900220253650395\n",
      "Current value of the loss function:  0.17345312070575025\n",
      "Current value of the loss function:  0.17345312279197483\n",
      "Current value of the loss function:  0.17345311957181733\n",
      "Current value of the loss function:  0.173453119054822\n",
      "Current value of the loss function:  0.17345312070575022\n",
      "Current value of the loss function:  0.17345312070575156\n",
      "Current value of the loss function:  0.17345312075918584\n",
      "Current value of the loss function:  0.17345312252363057\n",
      "Current value of the loss function:  0.17345312070575042\n",
      "Current value of the loss function:  0.1734531207057528\n",
      "Current value of the loss function:  0.17345312075975253\n",
      "Current value of the loss function:  0.17345312120649434\n",
      "Current value of the loss function:  0.1734531207057501\n",
      "Current value of the loss function:  0.1734531207057509\n",
      "Current value of the loss function:  0.17345312345338432\n",
      "Current value of the loss function:  0.17345312081175013\n",
      "Current value of the loss function:  0.17345312070574945\n",
      "Current value of the loss function:  0.17345312070575106\n",
      "Current value of the loss function:  0.17345312092926637\n",
      "Current value of the loss function:  0.17345312174293384\n",
      "Current value of the loss function:  0.1734531207057512\n",
      "Current value of the loss function:  0.17345312070574911\n",
      "Current value of the loss function:  0.17345312070824256\n",
      "Current value of the loss function:  0.17345312275226304\n",
      "Current value of the loss function:  0.1734531207057504\n",
      "Current value of the loss function:  0.1734531207057509\n",
      "Current value of the loss function:  0.17345312013563396\n",
      "Current value of the loss function:  0.17345312131776394\n",
      "Current value of the loss function:  0.17345312070574911\n",
      "Current value of the loss function:  0.17345312070575075\n",
      "Current value of the loss function:  0.1734531206023481\n",
      "Current value of the loss function:  0.17345312260980927\n",
      "Current value of the loss function:  0.1734531207057496\n",
      "Current value of the loss function:  0.17345312070575122\n",
      "Current value of the loss function:  0.17345312024194803\n",
      "Current value of the loss function:  0.17345311890785114\n",
      "Current value of the loss function:  0.17345312070574995\n",
      "Current value of the loss function:  0.1734531207057485\n",
      "Current value of the loss function:  0.17345311912710593\n",
      "Current value of the loss function:  0.17345312135641067\n",
      "Current value of the loss function:  0.17345312070574978\n",
      "Current value of the loss function:  0.17345312070575122\n",
      "Current value of the loss function:  0.17345312070575025\n",
      "Current value of the loss function:  0.16631671321703148\n",
      "Current value of the loss function:  0.1663167144064968\n",
      "Current value of the loss function:  0.16631671217311272\n",
      "Current value of the loss function:  0.16631671199889964\n",
      "Current value of the loss function:  0.16631671321703242\n",
      "Current value of the loss function:  0.16631671321703032\n",
      "Current value of the loss function:  0.16631671348818097\n",
      "Current value of the loss function:  0.16631671539222828\n",
      "Current value of the loss function:  0.16631671321702893\n",
      "Current value of the loss function:  0.16631671321703\n",
      "Current value of the loss function:  0.16631671327197411\n",
      "Current value of the loss function:  0.166316713672116\n",
      "Current value of the loss function:  0.16631671321703\n",
      "Current value of the loss function:  0.1663167132170305\n",
      "Current value of the loss function:  0.16631671424577688\n",
      "Current value of the loss function:  0.16631671352265326\n",
      "Current value of the loss function:  0.1663167132170297\n",
      "Current value of the loss function:  0.16631671321703068\n",
      "Current value of the loss function:  0.16631671345172405\n",
      "Current value of the loss function:  0.1663167146820593\n",
      "Current value of the loss function:  0.16631671321703112\n",
      "Current value of the loss function:  0.16631671321703195\n",
      "Current value of the loss function:  0.16631671306301835\n",
      "Current value of the loss function:  0.16631671481141838\n",
      "Current value of the loss function:  0.16631671321703229\n",
      "Current value of the loss function:  0.16631671321702984\n",
      "Current value of the loss function:  0.16631671289470468\n",
      "Current value of the loss function:  0.16631671393593334\n",
      "Current value of the loss function:  0.16631671321703148\n",
      "Current value of the loss function:  0.16631671321703054\n",
      "Current value of the loss function:  0.16631671303484205\n",
      "Current value of the loss function:  0.1663167138696212\n",
      "Current value of the loss function:  0.16631671321703084\n",
      "Current value of the loss function:  0.16631671321703248\n",
      "Current value of the loss function:  0.16631671236666537\n",
      "Current value of the loss function:  0.166316711833049\n",
      "Current value of the loss function:  0.16631671321703195\n",
      "Current value of the loss function:  0.1663167132170302\n",
      "Current value of the loss function:  0.1663167127447867\n",
      "Current value of the loss function:  0.16631671382794366\n",
      "Current value of the loss function:  0.16631671321703212\n",
      "Current value of the loss function:  0.16631671321703162\n",
      "Current value of the loss function:  0.16631671321703148\n",
      "Current value of the loss function:  0.16207220999109487\n",
      "Current value of the loss function:  0.16207221013239215\n",
      "Current value of the loss function:  0.1620722100392818\n",
      "Current value of the loss function:  0.16207220953608076\n",
      "Current value of the loss function:  0.16207220999109292\n",
      "Current value of the loss function:  0.16207220999109587\n",
      "Current value of the loss function:  0.16207221030326285\n",
      "Current value of the loss function:  0.1620722104571244\n",
      "Current value of the loss function:  0.16207220999109503\n",
      "Current value of the loss function:  0.16207220999109553\n",
      "Current value of the loss function:  0.16207221008617198\n",
      "Current value of the loss function:  0.1620722094827996\n",
      "Current value of the loss function:  0.16207220999109292\n",
      "Current value of the loss function:  0.16207220999109487\n",
      "Current value of the loss function:  0.1620722093927868\n",
      "Current value of the loss function:  0.1620722100139167\n",
      "Current value of the loss function:  0.16207220999109406\n",
      "Current value of the loss function:  0.16207220999109392\n",
      "Current value of the loss function:  0.16207221003422406\n",
      "Current value of the loss function:  0.1620722105756212\n",
      "Current value of the loss function:  0.16207220999109487\n",
      "Current value of the loss function:  0.1620722099910947\n",
      "Current value of the loss function:  0.16207220963861235\n",
      "Current value of the loss function:  0.16207221027378443\n",
      "Current value of the loss function:  0.16207220999109537\n",
      "Current value of the loss function:  0.1620722099910947\n",
      "Current value of the loss function:  0.16207220959626942\n",
      "Current value of the loss function:  0.16207221023939591\n",
      "Current value of the loss function:  0.16207220999109537\n",
      "Current value of the loss function:  0.16207220999109379\n",
      "Current value of the loss function:  0.16207220984136544\n",
      "Current value of the loss function:  0.16207221157701723\n",
      "Current value of the loss function:  0.16207220999109442\n",
      "Current value of the loss function:  0.1620722099910947\n",
      "Current value of the loss function:  0.1620722104238826\n",
      "Current value of the loss function:  0.16207220979788833\n",
      "Current value of the loss function:  0.16207220999109537\n",
      "Current value of the loss function:  0.16207220999109487\n",
      "Current value of the loss function:  0.16207221021017218\n",
      "Current value of the loss function:  0.16207221056276366\n",
      "Current value of the loss function:  0.1620722099910952\n",
      "Current value of the loss function:  0.1620722099910944\n",
      "Current value of the loss function:  0.16207220999109487\n",
      "Current value of the loss function:  0.16034270026755684\n",
      "Current value of the loss function:  0.16034269981220897\n",
      "Current value of the loss function:  0.16034270038289622\n",
      "Current value of the loss function:  0.16034270028532138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.1603427002675543\n",
      "Current value of the loss function:  0.1603427002675559\n",
      "Current value of the loss function:  0.16034270032765896\n",
      "Current value of the loss function:  0.1603427005877177\n",
      "Current value of the loss function:  0.16034270026755607\n",
      "Current value of the loss function:  0.1603427002675575\n",
      "Current value of the loss function:  0.16034270034290615\n",
      "Current value of the loss function:  0.16034269992067196\n",
      "Current value of the loss function:  0.16034270026755704\n",
      "Current value of the loss function:  0.16034270026755704\n",
      "Current value of the loss function:  0.16034270010817483\n",
      "Current value of the loss function:  0.1603427002539861\n",
      "Current value of the loss function:  0.16034270026755668\n",
      "Current value of the loss function:  0.16034270026755576\n",
      "Current value of the loss function:  0.16034270036146\n",
      "Current value of the loss function:  0.16034270040971726\n",
      "Current value of the loss function:  0.16034270026755737\n",
      "Current value of the loss function:  0.1603427002675567\n",
      "Current value of the loss function:  0.16034270024469766\n",
      "Current value of the loss function:  0.16034270017455463\n",
      "Current value of the loss function:  0.16034270026755607\n",
      "Current value of the loss function:  0.1603427002675567\n",
      "Current value of the loss function:  0.16034270011826593\n",
      "Current value of the loss function:  0.16034270038615517\n",
      "Current value of the loss function:  0.16034270026755865\n",
      "Current value of the loss function:  0.16034270026755718\n",
      "Current value of the loss function:  0.16034270005087042\n",
      "Current value of the loss function:  0.16034270107196613\n",
      "Current value of the loss function:  0.16034270026755798\n",
      "Current value of the loss function:  0.1603427002675588\n",
      "Current value of the loss function:  0.16034270035092338\n",
      "Current value of the loss function:  0.16034270022626534\n",
      "Current value of the loss function:  0.1603427002675572\n",
      "Current value of the loss function:  0.1603427002675559\n",
      "Current value of the loss function:  0.1603427005156059\n",
      "Current value of the loss function:  0.16034270053248575\n",
      "Current value of the loss function:  0.16034270026755704\n",
      "Current value of the loss function:  0.1603427002675572\n",
      "Current value of the loss function:  0.16034270026755684\n",
      "Current value of the loss function:  0.15843812575837551\n",
      "Current value of the loss function:  0.15843812507383045\n",
      "Current value of the loss function:  0.15843812573914612\n",
      "Current value of the loss function:  0.15843812626526538\n",
      "Current value of the loss function:  0.15843812575837632\n",
      "Current value of the loss function:  0.15843812575837682\n",
      "Current value of the loss function:  0.15843812560736945\n",
      "Current value of the loss function:  0.1584381258194915\n",
      "Current value of the loss function:  0.15843812575837776\n",
      "Current value of the loss function:  0.15843812575837743\n",
      "Current value of the loss function:  0.15843812581035482\n",
      "Current value of the loss function:  0.15843812575113086\n",
      "Current value of the loss function:  0.15843812575837504\n",
      "Current value of the loss function:  0.15843812575837585\n",
      "Current value of the loss function:  0.15843812581700428\n",
      "Current value of the loss function:  0.15843812548816272\n",
      "Current value of the loss function:  0.1584381257583755\n",
      "Current value of the loss function:  0.15843812575837518\n",
      "Current value of the loss function:  0.15843812587710174\n",
      "Current value of the loss function:  0.15843812526567236\n",
      "Current value of the loss function:  0.15843812575837551\n",
      "Current value of the loss function:  0.15843812575837699\n",
      "Current value of the loss function:  0.15843812597268472\n",
      "Current value of the loss function:  0.15843812520109232\n",
      "Current value of the loss function:  0.15843812575837388\n",
      "Current value of the loss function:  0.15843812575837585\n",
      "Current value of the loss function:  0.1584381258966235\n",
      "Current value of the loss function:  0.15843812581090133\n",
      "Current value of the loss function:  0.15843812575837585\n",
      "Current value of the loss function:  0.15843812575837488\n",
      "Current value of the loss function:  0.15843812544136746\n",
      "Current value of the loss function:  0.15843812648602856\n",
      "Current value of the loss function:  0.15843812575837618\n",
      "Current value of the loss function:  0.15843812575837538\n",
      "Current value of the loss function:  0.15843812557617534\n",
      "Current value of the loss function:  0.1584381259572626\n",
      "Current value of the loss function:  0.15843812575837488\n",
      "Current value of the loss function:  0.15843812575837665\n",
      "Current value of the loss function:  0.1584381256746451\n",
      "Current value of the loss function:  0.1584381256066162\n",
      "Current value of the loss function:  0.158438125758376\n",
      "Current value of the loss function:  0.158438125758376\n",
      "Current value of the loss function:  0.15843812575837551\n",
      "Current value of the loss function:  0.15469773087961058\n",
      "Current value of the loss function:  0.15469772934985032\n",
      "Current value of the loss function:  0.15469773083020374\n",
      "Current value of the loss function:  0.15469773233223547\n",
      "Current value of the loss function:  0.15469773087960897\n",
      "Current value of the loss function:  0.15469773087960784\n",
      "Current value of the loss function:  0.154697730525741\n",
      "Current value of the loss function:  0.1546977306758984\n",
      "Current value of the loss function:  0.15469773087961022\n",
      "Current value of the loss function:  0.154697730879609\n",
      "Current value of the loss function:  0.15469773090621122\n",
      "Current value of the loss function:  0.1546977310617603\n",
      "Current value of the loss function:  0.15469773087961042\n",
      "Current value of the loss function:  0.15469773087960995\n",
      "Current value of the loss function:  0.154697731148023\n",
      "Current value of the loss function:  0.15469773017581243\n",
      "Current value of the loss function:  0.15469773087961042\n",
      "Current value of the loss function:  0.15469773087961075\n",
      "Current value of the loss function:  0.15469773105078974\n",
      "Current value of the loss function:  0.15469772945411017\n",
      "Current value of the loss function:  0.15469773087961058\n",
      "Current value of the loss function:  0.15469773087961042\n",
      "Current value of the loss function:  0.15469773147203147\n",
      "Current value of the loss function:  0.1546977292004814\n",
      "Current value of the loss function:  0.15469773087961108\n",
      "Current value of the loss function:  0.15469773087961042\n",
      "Current value of the loss function:  0.1546977312851897\n",
      "Current value of the loss function:  0.15469773062421985\n",
      "Current value of the loss function:  0.15469773087961075\n",
      "Current value of the loss function:  0.1546977308796117\n",
      "Current value of the loss function:  0.15469773034028508\n",
      "Current value of the loss function:  0.15469773150635532\n",
      "Current value of the loss function:  0.15469773087961122\n",
      "Current value of the loss function:  0.1546977308796096\n",
      "Current value of the loss function:  0.15469773062593936\n",
      "Current value of the loss function:  0.15469773141870732\n",
      "Current value of the loss function:  0.15469773087961028\n",
      "Current value of the loss function:  0.15469773087960995\n",
      "Current value of the loss function:  0.15469773052041538\n",
      "Current value of the loss function:  0.15469773014984137\n",
      "Current value of the loss function:  0.15469773087961075\n",
      "Current value of the loss function:  0.15469773087961108\n",
      "Current value of the loss function:  0.15469773087961058\n",
      "Current value of the loss function:  0.14937870160549993\n",
      "Current value of the loss function:  0.1493786938633599\n",
      "Current value of the loss function:  0.1493787014438912\n",
      "Current value of the loss function:  0.14937870804031275\n",
      "Current value of the loss function:  0.1493787016055004\n",
      "Current value of the loss function:  0.14937870160550298\n",
      "Current value of the loss function:  0.14937870047409885\n",
      "Current value of the loss function:  0.14937870068874887\n",
      "Current value of the loss function:  0.14937870160550332\n",
      "Current value of the loss function:  0.14937870160550284\n",
      "Current value of the loss function:  0.14937870162327757\n",
      "Current value of the loss function:  0.14937870240698303\n",
      "Current value of the loss function:  0.14937870160550187\n",
      "Current value of the loss function:  0.1493787016055004\n",
      "Current value of the loss function:  0.1493787028617754\n",
      "Current value of the loss function:  0.14937869950888602\n",
      "Current value of the loss function:  0.1493787016055014\n",
      "Current value of the loss function:  0.14937870160550007\n",
      "Current value of the loss function:  0.14937870196548775\n",
      "Current value of the loss function:  0.14937869610454257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.14937870160549976\n",
      "Current value of the loss function:  0.14937870160550168\n",
      "Current value of the loss function:  0.14937870366313152\n",
      "Current value of the loss function:  0.14937869425302172\n",
      "Current value of the loss function:  0.1493787016055015\n",
      "Current value of the loss function:  0.14937870160550007\n",
      "Current value of the loss function:  0.14937870327986164\n",
      "Current value of the loss function:  0.14937869910183607\n",
      "Current value of the loss function:  0.14937870160549974\n",
      "Current value of the loss function:  0.14937870160549924\n",
      "Current value of the loss function:  0.14937870114625432\n",
      "Current value of the loss function:  0.14937870154308852\n",
      "Current value of the loss function:  0.14937870160550104\n",
      "Current value of the loss function:  0.1493787016054983\n",
      "Current value of the loss function:  0.14937870108404883\n",
      "Current value of the loss function:  0.14937870389766303\n",
      "Current value of the loss function:  0.1493787016055007\n",
      "Current value of the loss function:  0.1493787016054999\n",
      "Current value of the loss function:  0.1493787001288199\n",
      "Current value of the loss function:  0.149378698174847\n",
      "Current value of the loss function:  0.14937870160549893\n",
      "Current value of the loss function:  0.14937870160550024\n",
      "Current value of the loss function:  0.14937870160549993\n",
      "Current value of the loss function:  0.1492962534502897\n",
      "Current value of the loss function:  0.1492962499336885\n",
      "Current value of the loss function:  0.14929625335820523\n",
      "Current value of the loss function:  0.14929625660381043\n",
      "Current value of the loss function:  0.14929625345028716\n",
      "Current value of the loss function:  0.14929625345028813\n",
      "Current value of the loss function:  0.14929625280635014\n",
      "Current value of the loss function:  0.14929625295794632\n",
      "Current value of the loss function:  0.1492962534502907\n",
      "Current value of the loss function:  0.14929625345029102\n",
      "Current value of the loss function:  0.14929625345079742\n",
      "Current value of the loss function:  0.14929625381945041\n",
      "Current value of the loss function:  0.14929625345029185\n",
      "Current value of the loss function:  0.14929625345029135\n",
      "Current value of the loss function:  0.14929625405236496\n",
      "Current value of the loss function:  0.1492962522108818\n",
      "Current value of the loss function:  0.1492962534502891\n",
      "Current value of the loss function:  0.14929625345028893\n",
      "Current value of the loss function:  0.1492962536945108\n",
      "Current value of the loss function:  0.14929625056888451\n",
      "Current value of the loss function:  0.14929625345028874\n",
      "Current value of the loss function:  0.14929625345029005\n",
      "Current value of the loss function:  0.1492962545882803\n",
      "Current value of the loss function:  0.14929624981539213\n",
      "Current value of the loss function:  0.14929625345029005\n",
      "Current value of the loss function:  0.1492962534502881\n",
      "Current value of the loss function:  0.14929625428025514\n",
      "Current value of the loss function:  0.14929625245583925\n",
      "Current value of the loss function:  0.14929625345028844\n",
      "Current value of the loss function:  0.14929625345029038\n",
      "Current value of the loss function:  0.14929625268866653\n",
      "Current value of the loss function:  0.14929625413541717\n",
      "Current value of the loss function:  0.14929625345028844\n",
      "Current value of the loss function:  0.1492962534502891\n",
      "Current value of the loss function:  0.14929625309547526\n",
      "Current value of the loss function:  0.1492962545920858\n",
      "Current value of the loss function:  0.1492962534502899\n",
      "Current value of the loss function:  0.1492962534502897\n",
      "Current value of the loss function:  0.14929625268621\n",
      "Current value of the loss function:  0.14929625177184555\n",
      "Current value of the loss function:  0.1492962534502902\n",
      "Current value of the loss function:  0.14929625345028985\n",
      "Current value of the loss function:  0.1492962534502897\n",
      "Current value of the loss function:  0.18620210237899013\n",
      "Current value of the loss function:  0.18620209255676654\n",
      "Current value of the loss function:  0.18620210216431518\n",
      "Current value of the loss function:  0.18620211074861479\n",
      "Current value of the loss function:  0.18620210237899099\n",
      "Current value of the loss function:  0.18620210237898968\n",
      "Current value of the loss function:  0.18620210087704353\n",
      "Current value of the loss function:  0.18620210093573267\n",
      "Current value of the loss function:  0.18620210237898885\n",
      "Current value of the loss function:  0.18620210237898938\n",
      "Current value of the loss function:  0.1862021024499943\n",
      "Current value of the loss function:  0.18620210397711637\n",
      "Current value of the loss function:  0.1862021023789882\n",
      "Current value of the loss function:  0.1862021023789881\n",
      "Current value of the loss function:  0.186202104120329\n",
      "Current value of the loss function:  0.18620209940738738\n",
      "Current value of the loss function:  0.18620210237898982\n",
      "Current value of the loss function:  0.1862021023789895\n",
      "Current value of the loss function:  0.18620210283032249\n",
      "Current value of the loss function:  0.18620209501015733\n",
      "Current value of the loss function:  0.18620210237898918\n",
      "Current value of the loss function:  0.18620210237898868\n",
      "Current value of the loss function:  0.1862021051571064\n",
      "Current value of the loss function:  0.1862020926001755\n",
      "Current value of the loss function:  0.18620210237898807\n",
      "Current value of the loss function:  0.18620210237899\n",
      "Current value of the loss function:  0.18620210494920605\n",
      "Current value of the loss function:  0.18620209952422095\n",
      "Current value of the loss function:  0.18620210237898965\n",
      "Current value of the loss function:  0.18620210237898965\n",
      "Current value of the loss function:  0.1862021033262369\n",
      "Current value of the loss function:  0.1862020994049796\n",
      "Current value of the loss function:  0.18620210237898965\n",
      "Current value of the loss function:  0.18620210237898888\n",
      "Current value of the loss function:  0.18620210169075269\n",
      "Current value of the loss function:  0.18620210537810444\n",
      "Current value of the loss function:  0.18620210237898935\n",
      "Current value of the loss function:  0.18620210237899032\n",
      "Current value of the loss function:  0.18620210029652892\n",
      "Current value of the loss function:  0.1862020978288345\n",
      "Current value of the loss function:  0.18620210237898946\n",
      "Current value of the loss function:  0.18620210237899049\n",
      "Current value of the loss function:  0.18620210237899013\n",
      "Current value of the loss function:  0.1454073502190982\n",
      "Current value of the loss function:  0.14540734465147828\n",
      "Current value of the loss function:  0.14540735009161804\n",
      "Current value of the loss function:  0.14540735493181361\n",
      "Current value of the loss function:  0.14540735021909706\n",
      "Current value of the loss function:  0.14540735021909756\n",
      "Current value of the loss function:  0.14540734933522204\n",
      "Current value of the loss function:  0.14540734953921539\n",
      "Current value of the loss function:  0.14540735021909754\n",
      "Current value of the loss function:  0.14540735021909607\n",
      "Current value of the loss function:  0.1454073502173115\n",
      "Current value of the loss function:  0.14540735077546177\n",
      "Current value of the loss function:  0.1454073502190977\n",
      "Current value of the loss function:  0.1454073502190969\n",
      "Current value of the loss function:  0.14540735110339786\n",
      "Current value of the loss function:  0.1454073485811802\n",
      "Current value of the loss function:  0.1454073502190972\n",
      "Current value of the loss function:  0.1454073502190974\n",
      "Current value of the loss function:  0.14540735052503256\n",
      "Current value of the loss function:  0.14540734607526595\n",
      "Current value of the loss function:  0.14540735021909784\n",
      "Current value of the loss function:  0.14540735021909867\n",
      "Current value of the loss function:  0.14540735181966777\n",
      "Current value of the loss function:  0.145407344770256\n",
      "Current value of the loss function:  0.14540735021909834\n",
      "Current value of the loss function:  0.14540735021909898\n",
      "Current value of the loss function:  0.1454073514752712\n",
      "Current value of the loss function:  0.14540734852246628\n",
      "Current value of the loss function:  0.1454073502190972\n",
      "Current value of the loss function:  0.14540735021909656\n",
      "Current value of the loss function:  0.14540734946260514\n",
      "Current value of the loss function:  0.1454073508942876\n",
      "Current value of the loss function:  0.14540735021909948\n",
      "Current value of the loss function:  0.14540735021909723\n",
      "Current value of the loss function:  0.14540734977009628\n",
      "Current value of the loss function:  0.1454073519113327\n",
      "Current value of the loss function:  0.14540735021909884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.14540735021909915\n",
      "Current value of the loss function:  0.14540734910212796\n",
      "Current value of the loss function:  0.14540734771577174\n",
      "Current value of the loss function:  0.14540735021909854\n",
      "Current value of the loss function:  0.14540735021909723\n",
      "Current value of the loss function:  0.1454073502190982\n",
      "Current value of the loss function:  0.14343344104481087\n",
      "Current value of the loss function:  0.1434334337380385\n",
      "Current value of the loss function:  0.14343344091278729\n",
      "Current value of the loss function:  0.14343344727101062\n",
      "Current value of the loss function:  0.14343344104481265\n",
      "Current value of the loss function:  0.1434334410448133\n",
      "Current value of the loss function:  0.14343343970536523\n",
      "Current value of the loss function:  0.14343343982975812\n",
      "Current value of the loss function:  0.14343344104481104\n",
      "Current value of the loss function:  0.14343344104481212\n",
      "Current value of the loss function:  0.14343344106221095\n",
      "Current value of the loss function:  0.14343344193569726\n",
      "Current value of the loss function:  0.1434334410448107\n",
      "Current value of the loss function:  0.14343344104481165\n",
      "Current value of the loss function:  0.14343344257967225\n",
      "Current value of the loss function:  0.1434334392322413\n",
      "Current value of the loss function:  0.14343344104481165\n",
      "Current value of the loss function:  0.14343344104481262\n",
      "Current value of the loss function:  0.14343344136989747\n",
      "Current value of the loss function:  0.14343343510591908\n",
      "Current value of the loss function:  0.14343344104481165\n",
      "Current value of the loss function:  0.14343344104480993\n",
      "Current value of the loss function:  0.1434334432276153\n",
      "Current value of the loss function:  0.14343343394589125\n",
      "Current value of the loss function:  0.14343344104481037\n",
      "Current value of the loss function:  0.14343344104481118\n",
      "Current value of the loss function:  0.14343344267420569\n",
      "Current value of the loss function:  0.14343343853981752\n",
      "Current value of the loss function:  0.1434334410448107\n",
      "Current value of the loss function:  0.1434334410448107\n",
      "Current value of the loss function:  0.14343344068268327\n",
      "Current value of the loss function:  0.14343344103990135\n",
      "Current value of the loss function:  0.14343344104481215\n",
      "Current value of the loss function:  0.14343344104481215\n",
      "Current value of the loss function:  0.14343344053034063\n",
      "Current value of the loss function:  0.1434334432623806\n",
      "Current value of the loss function:  0.14343344104481054\n",
      "Current value of the loss function:  0.1434334410448115\n",
      "Current value of the loss function:  0.14343343931552868\n",
      "Current value of the loss function:  0.1434334374239128\n",
      "Current value of the loss function:  0.1434334410448102\n",
      "Current value of the loss function:  0.14343344104481084\n",
      "Current value of the loss function:  0.14343344104481087\n",
      "Current value of the loss function:  0.13990087651217512\n",
      "Current value of the loss function:  0.1399008697304542\n",
      "Current value of the loss function:  0.13990087638860857\n",
      "Current value of the loss function:  0.1399008823570613\n",
      "Current value of the loss function:  0.13990087651217645\n",
      "Current value of the loss function:  0.13990087651217692\n",
      "Current value of the loss function:  0.1399008752375723\n",
      "Current value of the loss function:  0.13990087529055256\n",
      "Current value of the loss function:  0.139900876512174\n",
      "Current value of the loss function:  0.1399008765121748\n",
      "Current value of the loss function:  0.1399008765231598\n",
      "Current value of the loss function:  0.13990087729536022\n",
      "Current value of the loss function:  0.1399008765121753\n",
      "Current value of the loss function:  0.1399008765121766\n",
      "Current value of the loss function:  0.13990087797866804\n",
      "Current value of the loss function:  0.13990087484169783\n",
      "Current value of the loss function:  0.13990087651217498\n",
      "Current value of the loss function:  0.13990087651217464\n",
      "Current value of the loss function:  0.13990087679603\n",
      "Current value of the loss function:  0.1399008708765777\n",
      "Current value of the loss function:  0.13990087651217403\n",
      "Current value of the loss function:  0.13990087651217384\n",
      "Current value of the loss function:  0.13990087856123481\n",
      "Current value of the loss function:  0.1399008698908801\n",
      "Current value of the loss function:  0.13990087651217545\n",
      "Current value of the loss function:  0.13990087651217595\n",
      "Current value of the loss function:  0.13990087804578855\n",
      "Current value of the loss function:  0.13990087407180715\n",
      "Current value of the loss function:  0.13990087651217528\n",
      "Current value of the loss function:  0.13990087651217545\n",
      "Current value of the loss function:  0.13990087601055262\n",
      "Current value of the loss function:  0.13990087667489037\n",
      "Current value of the loss function:  0.13990087651217498\n",
      "Current value of the loss function:  0.13990087651217498\n",
      "Current value of the loss function:  0.13990087606699167\n",
      "Current value of the loss function:  0.13990087857581138\n",
      "Current value of the loss function:  0.13990087651217495\n",
      "Current value of the loss function:  0.13990087651217545\n",
      "Current value of the loss function:  0.13990087484475808\n",
      "Current value of the loss function:  0.1399008730636881\n",
      "Current value of the loss function:  0.13990087651217464\n",
      "Current value of the loss function:  0.13990087651217464\n",
      "Current value of the loss function:  0.13990087651217512\n",
      "Current value of the loss function:  0.13328249306945344\n",
      "Current value of the loss function:  0.1332824869535856\n",
      "Current value of the loss function:  0.1332824929418753\n",
      "Current value of the loss function:  0.13328249845434395\n",
      "Current value of the loss function:  0.13328249306945117\n",
      "Current value of the loss function:  0.13328249306945197\n",
      "Current value of the loss function:  0.13328249193125827\n",
      "Current value of the loss function:  0.13328249183178503\n",
      "Current value of the loss function:  0.13328249306945245\n",
      "Current value of the loss function:  0.1332824930694518\n",
      "Current value of the loss function:  0.13328249307495413\n",
      "Current value of the loss function:  0.1332824936752294\n",
      "Current value of the loss function:  0.13328249306945392\n",
      "Current value of the loss function:  0.13328249306945408\n",
      "Current value of the loss function:  0.13328249442555382\n",
      "Current value of the loss function:  0.13328249149967253\n",
      "Current value of the loss function:  0.13328249306945264\n",
      "Current value of the loss function:  0.1332824930694526\n",
      "Current value of the loss function:  0.13328249330830602\n",
      "Current value of the loss function:  0.13328248792617217\n",
      "Current value of the loss function:  0.13328249306945375\n",
      "Current value of the loss function:  0.13328249306945278\n",
      "Current value of the loss function:  0.13328249492469557\n",
      "Current value of the loss function:  0.13328248699967382\n",
      "Current value of the loss function:  0.13328249306945436\n",
      "Current value of the loss function:  0.13328249306945214\n",
      "Current value of the loss function:  0.13328249471335113\n",
      "Current value of the loss function:  0.13328249076572102\n",
      "Current value of the loss function:  0.13328249306945408\n",
      "Current value of the loss function:  0.13328249306945408\n",
      "Current value of the loss function:  0.13328249246173357\n",
      "Current value of the loss function:  0.1332824933906047\n",
      "Current value of the loss function:  0.13328249306945375\n",
      "Current value of the loss function:  0.13328249306945358\n",
      "Current value of the loss function:  0.13328249272055476\n",
      "Current value of the loss function:  0.13328249493204697\n",
      "Current value of the loss function:  0.13328249306945408\n",
      "Current value of the loss function:  0.13328249306945358\n",
      "Current value of the loss function:  0.1332824914624912\n",
      "Current value of the loss function:  0.13328248981074822\n",
      "Current value of the loss function:  0.13328249306945358\n",
      "Current value of the loss function:  0.13328249306945264\n",
      "Current value of the loss function:  0.13328249306945344\n",
      "Current value of the loss function:  0.12101299576473608\n",
      "Current value of the loss function:  0.12101299062231075\n",
      "Current value of the loss function:  0.1210129956258475\n",
      "Current value of the loss function:  0.12101300051547963\n",
      "Current value of the loss function:  0.12101299576473805\n",
      "Current value of the loss function:  0.12101299576473673\n",
      "Current value of the loss function:  0.12101299481442844\n",
      "Current value of the loss function:  0.1210129946477719\n",
      "Current value of the loss function:  0.12101299576473803\n",
      "Current value of the loss function:  0.12101299576473692\n",
      "Current value of the loss function:  0.12101299576594259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.12101299610215273\n",
      "Current value of the loss function:  0.1210129957647369\n",
      "Current value of the loss function:  0.12101299576473674\n",
      "Current value of the loss function:  0.12101299694962772\n",
      "Current value of the loss function:  0.12101299444131156\n",
      "Current value of the loss function:  0.12101299576473451\n",
      "Current value of the loss function:  0.12101299576473515\n",
      "Current value of the loss function:  0.12101299597467076\n",
      "Current value of the loss function:  0.12101299132300546\n",
      "Current value of the loss function:  0.12101299576473529\n",
      "Current value of the loss function:  0.1210129957647358\n",
      "Current value of the loss function:  0.12101299735115865\n",
      "Current value of the loss function:  0.12101299047254228\n",
      "Current value of the loss function:  0.12101299576473577\n",
      "Current value of the loss function:  0.12101299576473626\n",
      "Current value of the loss function:  0.12101299731768266\n",
      "Current value of the loss function:  0.12101299350518172\n",
      "Current value of the loss function:  0.12101299576473483\n",
      "Current value of the loss function:  0.12101299576473515\n",
      "Current value of the loss function:  0.12101299502893843\n",
      "Current value of the loss function:  0.12101299611590204\n",
      "Current value of the loss function:  0.12101299576473512\n",
      "Current value of the loss function:  0.12101299576473688\n",
      "Current value of the loss function:  0.12101299546727956\n",
      "Current value of the loss function:  0.12101299739027593\n",
      "Current value of the loss function:  0.12101299576473612\n",
      "Current value of the loss function:  0.12101299576473659\n",
      "Current value of the loss function:  0.12101299430651333\n",
      "Current value of the loss function:  0.12101299269047781\n",
      "Current value of the loss function:  0.12101299576473723\n",
      "Current value of the loss function:  0.12101299576473612\n",
      "Current value of the loss function:  0.12101299576473608\n",
      "Current value of the loss function:  0.09898006295675338\n",
      "Current value of the loss function:  0.09898005925514995\n",
      "Current value of the loss function:  0.09898006282096732\n",
      "Current value of the loss function:  0.09898006650170228\n",
      "Current value of the loss function:  0.09898006295675114\n",
      "Current value of the loss function:  0.09898006295675145\n",
      "Current value of the loss function:  0.0989800623583988\n",
      "Current value of the loss function:  0.09898006205003206\n",
      "Current value of the loss function:  0.09898006295675368\n",
      "Current value of the loss function:  0.09898006295675531\n",
      "Current value of the loss function:  0.09898006295691002\n",
      "Current value of the loss function:  0.09898006290550784\n",
      "Current value of the loss function:  0.09898006295675367\n",
      "Current value of the loss function:  0.09898006295675335\n",
      "Current value of the loss function:  0.09898006374843508\n",
      "Current value of the loss function:  0.09898006200938685\n",
      "Current value of the loss function:  0.0989800629567524\n",
      "Current value of the loss function:  0.09898006295675384\n",
      "Current value of the loss function:  0.0989800631143604\n",
      "Current value of the loss function:  0.0989800598805981\n",
      "Current value of the loss function:  0.0989800629567545\n",
      "Current value of the loss function:  0.0989800629567532\n",
      "Current value of the loss function:  0.0989800641058874\n",
      "Current value of the loss function:  0.09898005887522267\n",
      "Current value of the loss function:  0.09898006295675273\n",
      "Current value of the loss function:  0.09898006295675466\n",
      "Current value of the loss function:  0.0989800646949378\n",
      "Current value of the loss function:  0.09898006112677242\n",
      "Current value of the loss function:  0.098980062956754\n",
      "Current value of the loss function:  0.09898006295675435\n",
      "Current value of the loss function:  0.0989800621310693\n",
      "Current value of the loss function:  0.0989800636578934\n",
      "Current value of the loss function:  0.09898006295675321\n",
      "Current value of the loss function:  0.0989800629567529\n",
      "Current value of the loss function:  0.09898006281846626\n",
      "Current value of the loss function:  0.09898006404815625\n",
      "Current value of the loss function:  0.09898006295675336\n",
      "Current value of the loss function:  0.09898006295675497\n",
      "Current value of the loss function:  0.09898006177563118\n",
      "Current value of the loss function:  0.09898006052010139\n",
      "Current value of the loss function:  0.09898006295675384\n",
      "Current value of the loss function:  0.09898006295675175\n",
      "Current value of the loss function:  0.09898006295675338\n",
      "Current value of the loss function:  0.06461274728736024\n",
      "Current value of the loss function:  0.06461274585349494\n",
      "Current value of the loss function:  0.06461274722915059\n",
      "Current value of the loss function:  0.06461274894867247\n",
      "Current value of the loss function:  0.06461274728736104\n",
      "Current value of the loss function:  0.06461274728736023\n",
      "Current value of the loss function:  0.06461274719262927\n",
      "Current value of the loss function:  0.06461274692398301\n",
      "Current value of the loss function:  0.06461274728736105\n",
      "Current value of the loss function:  0.06461274728736283\n",
      "Current value of the loss function:  0.06461274729125832\n",
      "Current value of the loss function:  0.06461274663947524\n",
      "Current value of the loss function:  0.06461274728736008\n",
      "Current value of the loss function:  0.06461274728736137\n",
      "Current value of the loss function:  0.0646127475077533\n",
      "Current value of the loss function:  0.06461274713619541\n",
      "Current value of the loss function:  0.06461274728736008\n",
      "Current value of the loss function:  0.06461274728736024\n",
      "Current value of the loss function:  0.06461274741045225\n",
      "Current value of the loss function:  0.06461274634541882\n",
      "Current value of the loss function:  0.06461274728736088\n",
      "Current value of the loss function:  0.06461274728736056\n",
      "Current value of the loss function:  0.06461274773985148\n",
      "Current value of the loss function:  0.06461274516240859\n",
      "Current value of the loss function:  0.06461274728735862\n",
      "Current value of the loss function:  0.06461274728735927\n",
      "Current value of the loss function:  0.06461274865910485\n",
      "Current value of the loss function:  0.06461274576385702\n",
      "Current value of the loss function:  0.06461274728735991\n",
      "Current value of the loss function:  0.06461274728735976\n",
      "Current value of the loss function:  0.06461274695814638\n",
      "Current value of the loss function:  0.06461274797200317\n",
      "Current value of the loss function:  0.06461274728736137\n",
      "Current value of the loss function:  0.0646127472873596\n",
      "Current value of the loss function:  0.06461274728824518\n",
      "Current value of the loss function:  0.06461274768995842\n",
      "Current value of the loss function:  0.06461274728735944\n",
      "Current value of the loss function:  0.06461274728736152\n",
      "Current value of the loss function:  0.06461274662573571\n",
      "Current value of the loss function:  0.06461274559560319\n",
      "Current value of the loss function:  0.06461274728735991\n",
      "Current value of the loss function:  0.06461274728736072\n",
      "Current value of the loss function:  0.06461274728736024\n",
      "Current value of the loss function:  0.045721100362344086\n",
      "Current value of the loss function:  0.0457211010270758\n",
      "Current value of the loss function:  0.04572110047422797\n",
      "Current value of the loss function:  0.04572109905885337\n",
      "Current value of the loss function:  0.04572110036234585\n",
      "Current value of the loss function:  0.04572110036234071\n",
      "Current value of the loss function:  0.04572110099898761\n",
      "Current value of the loss function:  0.045721101361349076\n",
      "Current value of the loss function:  0.0457211003623444\n",
      "Current value of the loss function:  0.04572110036234521\n",
      "Current value of the loss function:  0.04572110036754237\n",
      "Current value of the loss function:  0.04572109919714862\n",
      "Current value of the loss function:  0.045721100362342476\n",
      "Current value of the loss function:  0.04572110036234375\n",
      "Current value of the loss function:  0.04572109948592251\n",
      "Current value of the loss function:  0.04572110142292689\n",
      "Current value of the loss function:  0.04572110036234296\n",
      "Current value of the loss function:  0.04572110036234473\n",
      "Current value of the loss function:  0.0457211005416132\n",
      "Current value of the loss function:  0.04572110279127001\n",
      "Current value of the loss function:  0.045721100362343926\n",
      "Current value of the loss function:  0.04572110036234505\n",
      "Current value of the loss function:  0.04572109978941195\n",
      "Current value of the loss function:  0.045721100859992786\n",
      "Current value of the loss function:  0.045721100362344405\n",
      "Current value of the loss function:  0.04572110036234345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.04572110064763662\n",
      "Current value of the loss function:  0.04572110060865536\n",
      "Current value of the loss function:  0.04572110036234328\n",
      "Current value of the loss function:  0.04572110036234281\n",
      "Current value of the loss function:  0.04572110095566573\n",
      "Current value of the loss function:  0.045721100852945826\n",
      "Current value of the loss function:  0.045721100362344086\n",
      "Current value of the loss function:  0.045721100362344724\n",
      "Current value of the loss function:  0.045721100494365986\n",
      "Current value of the loss function:  0.04572109968480796\n",
      "Current value of the loss function:  0.04572110036234361\n",
      "Current value of the loss function:  0.04572110036234345\n",
      "Current value of the loss function:  0.045721100884152405\n",
      "Current value of the loss function:  0.04572110079099223\n",
      "Current value of the loss function:  0.045721100362344565\n",
      "Current value of the loss function:  0.04572110036234521\n",
      "Current value of the loss function:  0.045721100362344086\n",
      "Current value of the loss function:  0.04329184865430932\n",
      "Current value of the loss function:  0.043291848893275545\n",
      "Current value of the loss function:  0.04329184883363123\n",
      "Current value of the loss function:  0.04329184757626465\n",
      "Current value of the loss function:  0.04329184865430996\n",
      "Current value of the loss function:  0.043291848654309156\n",
      "Current value of the loss function:  0.04329184892234625\n",
      "Current value of the loss function:  0.04329184943013375\n",
      "Current value of the loss function:  0.043291848654308684\n",
      "Current value of the loss function:  0.043291848654308844\n",
      "Current value of the loss function:  0.04329184865634134\n",
      "Current value of the loss function:  0.04329184809016155\n",
      "Current value of the loss function:  0.04329184865430932\n",
      "Current value of the loss function:  0.04329184865430932\n",
      "Current value of the loss function:  0.043291848300199894\n",
      "Current value of the loss function:  0.043291849619153826\n",
      "Current value of the loss function:  0.04329184865431125\n",
      "Current value of the loss function:  0.043291848654310766\n",
      "Current value of the loss function:  0.043291848754637687\n",
      "Current value of the loss function:  0.043291850328874025\n",
      "Current value of the loss function:  0.04329184865431045\n",
      "Current value of the loss function:  0.0432918486543098\n",
      "Current value of the loss function:  0.04329184826212468\n",
      "Current value of the loss function:  0.04329184928633351\n",
      "Current value of the loss function:  0.043291848654308844\n",
      "Current value of the loss function:  0.04329184865430964\n",
      "Current value of the loss function:  0.04329184844996997\n",
      "Current value of the loss function:  0.043291848839964585\n",
      "Current value of the loss function:  0.04329184865430948\n",
      "Current value of the loss function:  0.04329184865431045\n",
      "Current value of the loss function:  0.04329184843963214\n",
      "Current value of the loss function:  0.04329184948080446\n",
      "Current value of the loss function:  0.04329184865430964\n",
      "Current value of the loss function:  0.04329184865430996\n",
      "Current value of the loss function:  0.04329184867143382\n",
      "Current value of the loss function:  0.04329184814023548\n",
      "Current value of the loss function:  0.04329184865430965\n",
      "Current value of the loss function:  0.04329184865430916\n",
      "Current value of the loss function:  0.043291849012359496\n",
      "Current value of the loss function:  0.04329184914282679\n",
      "Current value of the loss function:  0.04329184865431013\n",
      "Current value of the loss function:  0.04329184865431045\n",
      "Current value of the loss function:  0.04329184865430932\n",
      "Current value of the loss function:  0.04097486828178887\n",
      "Current value of the loss function:  0.040974868294313974\n",
      "Current value of the loss function:  0.04097486845067273\n",
      "Current value of the loss function:  0.04097486771486607\n",
      "Current value of the loss function:  0.040974868281787584\n",
      "Current value of the loss function:  0.040974868281785655\n",
      "Current value of the loss function:  0.040974868028334915\n",
      "Current value of the loss function:  0.04097486823026792\n",
      "Current value of the loss function:  0.040974868281787265\n",
      "Current value of the loss function:  0.040974868281788396\n",
      "Current value of the loss function:  0.04097486828136879\n",
      "Current value of the loss function:  0.04097486849708104\n",
      "Current value of the loss function:  0.04097486828178919\n",
      "Current value of the loss function:  0.04097486828178935\n",
      "Current value of the loss function:  0.04097486870930046\n",
      "Current value of the loss function:  0.04097486887779183\n",
      "Current value of the loss function:  0.04097486828178968\n",
      "Current value of the loss function:  0.040974868281789194\n",
      "Current value of the loss function:  0.04097486819585248\n",
      "Current value of the loss function:  0.0409748685052107\n",
      "Current value of the loss function:  0.04097486828178871\n",
      "Current value of the loss function:  0.040974868281788875\n",
      "Current value of the loss function:  0.040974868209923576\n",
      "Current value of the loss function:  0.04097486901353464\n",
      "Current value of the loss function:  0.040974868281787744\n",
      "Current value of the loss function:  0.04097486828178838\n",
      "Current value of the loss function:  0.0409748685321671\n",
      "Current value of the loss function:  0.04097486813587856\n",
      "Current value of the loss function:  0.04097486828178839\n",
      "Current value of the loss function:  0.04097486828178871\n",
      "Current value of the loss function:  0.040974868527169465\n",
      "Current value of the loss function:  0.040974869347079786\n",
      "Current value of the loss function:  0.04097486828179032\n",
      "Current value of the loss function:  0.04097486828178919\n",
      "Current value of the loss function:  0.04097486828919483\n",
      "Current value of the loss function:  0.04097486799503997\n",
      "Current value of the loss function:  0.040974868281789034\n",
      "Current value of the loss function:  0.04097486828178887\n",
      "Current value of the loss function:  0.04097486807608877\n",
      "Current value of the loss function:  0.04097486855146007\n",
      "Current value of the loss function:  0.04097486828179016\n",
      "Current value of the loss function:  0.04097486828178951\n",
      "Current value of the loss function:  0.04097486828178887\n",
      "Current value of the loss function:  0.040091818230475966\n",
      "Current value of the loss function:  0.04009181805558335\n",
      "Current value of the loss function:  0.04009181826529356\n",
      "Current value of the loss function:  0.04009181796466412\n",
      "Current value of the loss function:  0.04009181823047886\n",
      "Current value of the loss function:  0.04009181823047453\n",
      "Current value of the loss function:  0.0400918181528627\n",
      "Current value of the loss function:  0.04009181830247283\n",
      "Current value of the loss function:  0.040091818230475966\n",
      "Current value of the loss function:  0.040091818230475966\n",
      "Current value of the loss function:  0.04009181823025454\n",
      "Current value of the loss function:  0.04009181798032769\n",
      "Current value of the loss function:  0.040091818230475806\n",
      "Current value of the loss function:  0.04009181823047469\n",
      "Current value of the loss function:  0.04009181849257433\n",
      "Current value of the loss function:  0.04009181874615244\n",
      "Current value of the loss function:  0.040091818230475806\n",
      "Current value of the loss function:  0.040091818230475806\n",
      "Current value of the loss function:  0.040091818219948464\n",
      "Current value of the loss function:  0.04009181843132896\n",
      "Current value of the loss function:  0.040091818230476126\n",
      "Current value of the loss function:  0.04009181823047549\n",
      "Current value of the loss function:  0.040091817996935356\n",
      "Current value of the loss function:  0.040091818930583174\n",
      "Current value of the loss function:  0.04009181823047709\n",
      "Current value of the loss function:  0.04009181823047661\n",
      "Current value of the loss function:  0.04009181809335488\n",
      "Current value of the loss function:  0.04009181804469012\n",
      "Current value of the loss function:  0.04009181823047468\n",
      "Current value of the loss function:  0.04009181823047741\n",
      "Current value of the loss function:  0.04009181861928777\n",
      "Current value of the loss function:  0.040091818694419176\n",
      "Current value of the loss function:  0.04009181823047565\n",
      "Current value of the loss function:  0.04009181823047469\n",
      "Current value of the loss function:  0.04009181814720687\n",
      "Current value of the loss function:  0.040091818195519574\n",
      "Current value of the loss function:  0.040091818230474044\n",
      "Current value of the loss function:  0.040091818230476285\n",
      "Current value of the loss function:  0.04009181814572797\n",
      "Current value of the loss function:  0.04009181817964161\n",
      "Current value of the loss function:  0.04009181823047565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.04009181823047549\n",
      "Current value of the loss function:  0.040091818230475966\n",
      "Current value of the loss function:  0.039747900109681655\n",
      "Current value of the loss function:  0.03974790006621445\n",
      "Current value of the loss function:  0.039747900026968014\n",
      "Current value of the loss function:  0.039747899871926215\n",
      "Current value of the loss function:  0.03974790010968422\n",
      "Current value of the loss function:  0.039747900109681655\n",
      "Current value of the loss function:  0.039747900122323314\n",
      "Current value of the loss function:  0.03974790035163754\n",
      "Current value of the loss function:  0.03974790010968101\n",
      "Current value of the loss function:  0.039747900109683584\n",
      "Current value of the loss function:  0.039747900109503576\n",
      "Current value of the loss function:  0.039747899622979414\n",
      "Current value of the loss function:  0.039747900109681975\n",
      "Current value of the loss function:  0.03974790010968246\n",
      "Current value of the loss function:  0.03974790029095743\n",
      "Current value of the loss function:  0.039747900664855174\n",
      "Current value of the loss function:  0.03974790010968262\n",
      "Current value of the loss function:  0.03974790010968343\n",
      "Current value of the loss function:  0.039747900126147664\n",
      "Current value of the loss function:  0.03974790027602814\n",
      "Current value of the loss function:  0.039747900109681496\n",
      "Current value of the loss function:  0.039747900109681815\n",
      "Current value of the loss function:  0.039747899817641506\n",
      "Current value of the loss function:  0.039747900955697434\n",
      "Current value of the loss function:  0.03974790010968262\n",
      "Current value of the loss function:  0.03974790010968149\n",
      "Current value of the loss function:  0.0397479000945021\n",
      "Current value of the loss function:  0.0397479000663415\n",
      "Current value of the loss function:  0.0397479001096823\n",
      "Current value of the loss function:  0.03974790010968214\n",
      "Current value of the loss function:  0.03974790045786713\n",
      "Current value of the loss function:  0.039747900596128226\n",
      "Current value of the loss function:  0.03974790010968118\n",
      "Current value of the loss function:  0.03974790010968118\n",
      "Current value of the loss function:  0.03974790000750676\n",
      "Current value of the loss function:  0.039747900053352776\n",
      "Current value of the loss function:  0.039747900109683265\n",
      "Current value of the loss function:  0.03974790010968182\n",
      "Current value of the loss function:  0.039747900191203875\n",
      "Current value of the loss function:  0.03974790011490857\n",
      "Current value of the loss function:  0.03974790010968278\n",
      "Current value of the loss function:  0.03974790010968245\n",
      "Current value of the loss function:  0.039747900109681655\n",
      "Current value of the loss function:  0.03930497151243636\n",
      "Current value of the loss function:  0.03930497182068514\n",
      "Current value of the loss function:  0.039304971332516224\n",
      "Current value of the loss function:  0.03930497130904663\n",
      "Current value of the loss function:  0.0393049715124378\n",
      "Current value of the loss function:  0.03930497151243652\n",
      "Current value of the loss function:  0.039304971541723265\n",
      "Current value of the loss function:  0.03930497182006326\n",
      "Current value of the loss function:  0.03930497151243877\n",
      "Current value of the loss function:  0.03930497151243845\n",
      "Current value of the loss function:  0.03930497151400239\n",
      "Current value of the loss function:  0.03930497077703879\n",
      "Current value of the loss function:  0.03930497151243587\n",
      "Current value of the loss function:  0.03930497151243636\n",
      "Current value of the loss function:  0.03930497174941005\n",
      "Current value of the loss function:  0.039304972090143525\n",
      "Current value of the loss function:  0.03930497151243587\n",
      "Current value of the loss function:  0.03930497151243749\n",
      "Current value of the loss function:  0.03930497151934166\n",
      "Current value of the loss function:  0.03930497148721453\n",
      "Current value of the loss function:  0.03930497151243684\n",
      "Current value of the loss function:  0.03930497151243588\n",
      "Current value of the loss function:  0.03930497120561552\n",
      "Current value of the loss function:  0.03930497262040587\n",
      "Current value of the loss function:  0.0393049715124362\n",
      "Current value of the loss function:  0.03930497151243717\n",
      "Current value of the loss function:  0.039304971453172494\n",
      "Current value of the loss function:  0.039304971545053594\n",
      "Current value of the loss function:  0.0393049715124362\n",
      "Current value of the loss function:  0.039304971512436844\n",
      "Current value of the loss function:  0.03930497179820657\n",
      "Current value of the loss function:  0.039304972122281776\n",
      "Current value of the loss function:  0.03930497151243813\n",
      "Current value of the loss function:  0.03930497151243732\n",
      "Current value of the loss function:  0.03930497139161909\n",
      "Current value of the loss function:  0.0393049714095333\n",
      "Current value of the loss function:  0.03930497151243587\n",
      "Current value of the loss function:  0.03930497151243732\n",
      "Current value of the loss function:  0.039304971645702735\n",
      "Current value of the loss function:  0.03930497150580968\n",
      "Current value of the loss function:  0.03930497151243716\n",
      "Current value of the loss function:  0.03930497151243765\n",
      "Current value of the loss function:  0.03930497151243636\n",
      "Current value of the loss function:  0.038717242887050626\n",
      "Current value of the loss function:  0.03871724351395572\n",
      "Current value of the loss function:  0.03871724266672814\n",
      "Current value of the loss function:  0.03871724276485524\n",
      "Current value of the loss function:  0.03871724288704998\n",
      "Current value of the loss function:  0.038717242887047254\n",
      "Current value of the loss function:  0.038717242906611736\n",
      "Current value of the loss function:  0.038717243134296184\n",
      "Current value of the loss function:  0.038717242887049495\n",
      "Current value of the loss function:  0.038717242887049655\n",
      "Current value of the loss function:  0.03871724289110166\n",
      "Current value of the loss function:  0.03871724188013485\n",
      "Current value of the loss function:  0.03871724288704982\n",
      "Current value of the loss function:  0.03871724288705046\n",
      "Current value of the loss function:  0.03871724315488796\n",
      "Current value of the loss function:  0.03871724338626593\n",
      "Current value of the loss function:  0.03871724288705207\n",
      "Current value of the loss function:  0.038717242887050626\n",
      "Current value of the loss function:  0.03871724284969374\n",
      "Current value of the loss function:  0.03871724263714032\n",
      "Current value of the loss function:  0.03871724288704999\n",
      "Current value of the loss function:  0.038717242887049974\n",
      "Current value of the loss function:  0.038717242547620545\n",
      "Current value of the loss function:  0.03871724418382125\n",
      "Current value of the loss function:  0.03871724288704886\n",
      "Current value of the loss function:  0.038717242887049655\n",
      "Current value of the loss function:  0.03871724292682869\n",
      "Current value of the loss function:  0.03871724285722562\n",
      "Current value of the loss function:  0.03871724288705047\n",
      "Current value of the loss function:  0.03871724288704998\n",
      "Current value of the loss function:  0.03871724306032664\n",
      "Current value of the loss function:  0.038717243558496386\n",
      "Current value of the loss function:  0.0387172428870503\n",
      "Current value of the loss function:  0.038717242887049336\n",
      "Current value of the loss function:  0.03871724281017658\n",
      "Current value of the loss function:  0.03871724278865372\n",
      "Current value of the loss function:  0.03871724288705062\n",
      "Current value of the loss function:  0.038717242887049336\n",
      "Current value of the loss function:  0.038717242957068784\n",
      "Current value of the loss function:  0.03871724279580149\n",
      "Current value of the loss function:  0.038717242887050786\n",
      "Current value of the loss function:  0.03871724288705062\n",
      "Current value of the loss function:  0.038717242887050626\n",
      "Current value of the loss function:  0.03788607885530833\n",
      "Current value of the loss function:  0.03788607978092491\n",
      "Current value of the loss function:  0.037886078622636134\n",
      "Current value of the loss function:  0.0378860787774713\n",
      "Current value of the loss function:  0.03788607885530929\n",
      "Current value of the loss function:  0.03788607885531009\n",
      "Current value of the loss function:  0.0378860788413182\n",
      "Current value of the loss function:  0.03788607895046979\n",
      "Current value of the loss function:  0.03788607885530897\n",
      "Current value of the loss function:  0.037886078855308966\n",
      "Current value of the loss function:  0.03788607886028861\n",
      "Current value of the loss function:  0.03788607779479099\n",
      "Current value of the loss function:  0.03788607885530849\n",
      "Current value of the loss function:  0.03788607885530592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.03788607916871219\n",
      "Current value of the loss function:  0.03788607923052472\n",
      "Current value of the loss function:  0.03788607885530881\n",
      "Current value of the loss function:  0.03788607885530929\n",
      "Current value of the loss function:  0.03788607877397962\n",
      "Current value of the loss function:  0.037886078452308236\n",
      "Current value of the loss function:  0.037886078855308\n",
      "Current value of the loss function:  0.03788607885530753\n",
      "Current value of the loss function:  0.03788607853159139\n",
      "Current value of the loss function:  0.03788608020436916\n",
      "Current value of the loss function:  0.03788607885530752\n",
      "Current value of the loss function:  0.037886078855308654\n",
      "Current value of the loss function:  0.03788607891925438\n",
      "Current value of the loss function:  0.03788607877323123\n",
      "Current value of the loss function:  0.03788607885530769\n",
      "Current value of the loss function:  0.03788607885530865\n",
      "Current value of the loss function:  0.03788607891617319\n",
      "Current value of the loss function:  0.037886079593937694\n",
      "Current value of the loss function:  0.037886078855308654\n",
      "Current value of the loss function:  0.037886078855308494\n",
      "Current value of the loss function:  0.03788607881024394\n",
      "Current value of the loss function:  0.0378860787478357\n",
      "Current value of the loss function:  0.03788607885530576\n",
      "Current value of the loss function:  0.03788607885530897\n",
      "Current value of the loss function:  0.037886078857965674\n",
      "Current value of the loss function:  0.03788607870631974\n",
      "Current value of the loss function:  0.037886078855307204\n",
      "Current value of the loss function:  0.03788607885530769\n",
      "Current value of the loss function:  0.03788607885530833\n",
      "Current value of the loss function:  0.03665306244341636\n",
      "Current value of the loss function:  0.036653063312676724\n",
      "Current value of the loss function:  0.03665306226536677\n",
      "Current value of the loss function:  0.03665306245311541\n",
      "Current value of the loss function:  0.0366530624434178\n",
      "Current value of the loss function:  0.036653062443417324\n",
      "Current value of the loss function:  0.03665306239169196\n",
      "Current value of the loss function:  0.0366530623450133\n",
      "Current value of the loss function:  0.03665306244341588\n",
      "Current value of the loss function:  0.036653062443417164\n",
      "Current value of the loss function:  0.03665306244458204\n",
      "Current value of the loss function:  0.03665306166417582\n",
      "Current value of the loss function:  0.0366530624434178\n",
      "Current value of the loss function:  0.03665306244341636\n",
      "Current value of the loss function:  0.03665306271660716\n",
      "Current value of the loss function:  0.036653062592650755\n",
      "Current value of the loss function:  0.036653062443417324\n",
      "Current value of the loss function:  0.03665306244341619\n",
      "Current value of the loss function:  0.03665306233683606\n",
      "Current value of the loss function:  0.03665306199374787\n",
      "Current value of the loss function:  0.03665306244341684\n",
      "Current value of the loss function:  0.036653062443415874\n",
      "Current value of the loss function:  0.03665306220619185\n",
      "Current value of the loss function:  0.03665306347323606\n",
      "Current value of the loss function:  0.03665306244341636\n",
      "Current value of the loss function:  0.03665306244341716\n",
      "Current value of the loss function:  0.036653062562866864\n",
      "Current value of the loss function:  0.03665306227603567\n",
      "Current value of the loss function:  0.03665306244341668\n",
      "Current value of the loss function:  0.03665306244341555\n",
      "Current value of the loss function:  0.03665306237716745\n",
      "Current value of the loss function:  0.03665306294330256\n",
      "Current value of the loss function:  0.036653062443415874\n",
      "Current value of the loss function:  0.03665306244341684\n",
      "Current value of the loss function:  0.03665306246606381\n",
      "Current value of the loss function:  0.036653062396254946\n",
      "Current value of the loss function:  0.03665306244341604\n",
      "Current value of the loss function:  0.036653062443417324\n",
      "Current value of the loss function:  0.03665306234301864\n",
      "Current value of the loss function:  0.03665306222009949\n",
      "Current value of the loss function:  0.03665306244341748\n",
      "Current value of the loss function:  0.03665306244341652\n",
      "Current value of the loss function:  0.03665306244341636\n",
      "Current value of the loss function:  0.03580570965574386\n",
      "Current value of the loss function:  0.035805710042109744\n",
      "Current value of the loss function:  0.035805709579096616\n",
      "Current value of the loss function:  0.0358057096948519\n",
      "Current value of the loss function:  0.0358057096557453\n",
      "Current value of the loss function:  0.03580570965574579\n",
      "Current value of the loss function:  0.035805709618431124\n",
      "Current value of the loss function:  0.0358057094706012\n",
      "Current value of the loss function:  0.03580570965574434\n",
      "Current value of the loss function:  0.035805709655745144\n",
      "Current value of the loss function:  0.03580570965503061\n",
      "Current value of the loss function:  0.035805709532618635\n",
      "Current value of the loss function:  0.035805709655744505\n",
      "Current value of the loss function:  0.03580570965574547\n",
      "Current value of the loss function:  0.03580570978960378\n",
      "Current value of the loss function:  0.03580570960546801\n",
      "Current value of the loss function:  0.03580570965574386\n",
      "Current value of the loss function:  0.035805709655744984\n",
      "Current value of the loss function:  0.035805709587462625\n",
      "Current value of the loss function:  0.03580570942998746\n",
      "Current value of the loss function:  0.035805709655744505\n",
      "Current value of the loss function:  0.03580570965574354\n",
      "Current value of the loss function:  0.03580570957974593\n",
      "Current value of the loss function:  0.03580570999290539\n",
      "Current value of the loss function:  0.035805709655744186\n",
      "Current value of the loss function:  0.035805709655744665\n",
      "Current value of the loss function:  0.03580570971783134\n",
      "Current value of the loss function:  0.03580570952535013\n",
      "Current value of the loss function:  0.035805709655744346\n",
      "Current value of the loss function:  0.03580570965574322\n",
      "Current value of the loss function:  0.035805709585310846\n",
      "Current value of the loss function:  0.0358057097632181\n",
      "Current value of the loss function:  0.035805709655744186\n",
      "Current value of the loss function:  0.03580570965574386\n",
      "Current value of the loss function:  0.03580570967119242\n",
      "Current value of the loss function:  0.03580570967238682\n",
      "Current value of the loss function:  0.03580570965574386\n",
      "Current value of the loss function:  0.03580570965574659\n",
      "Current value of the loss function:  0.035805709556259294\n",
      "Current value of the loss function:  0.035805709483950954\n",
      "Current value of the loss function:  0.035805709655744346\n",
      "Current value of the loss function:  0.03580570965574354\n",
      "Current value of the loss function:  0.03580570965574386\n",
      "Current value of the loss function:  0.03565154185486566\n",
      "Current value of the loss function:  0.035651541964373486\n",
      "Current value of the loss function:  0.03565154184365647\n",
      "Current value of the loss function:  0.03565154186294975\n",
      "Current value of the loss function:  0.035651541854866305\n",
      "Current value of the loss function:  0.03565154185486566\n",
      "Current value of the loss function:  0.03565154184411267\n",
      "Current value of the loss function:  0.03565154178322075\n",
      "Current value of the loss function:  0.03565154185486695\n",
      "Current value of the loss function:  0.0356515418548655\n",
      "Current value of the loss function:  0.03565154185423713\n",
      "Current value of the loss function:  0.035651541858657904\n",
      "Current value of the loss function:  0.03565154185486582\n",
      "Current value of the loss function:  0.03565154185486711\n",
      "Current value of the loss function:  0.035651541883084975\n",
      "Current value of the loss function:  0.03565154182445889\n",
      "Current value of the loss function:  0.03565154185486598\n",
      "Current value of the loss function:  0.035651541854866624\n",
      "Current value of the loss function:  0.035651541837904394\n",
      "Current value of the loss function:  0.035651541810117766\n",
      "Current value of the loss function:  0.035651541854866305\n",
      "Current value of the loss function:  0.03565154185486534\n",
      "Current value of the loss function:  0.035651541854330476\n",
      "Current value of the loss function:  0.035651541911254345\n",
      "Current value of the loss function:  0.0356515418548639\n",
      "Current value of the loss function:  0.035651541854865985\n",
      "Current value of the loss function:  0.035651541880344514\n",
      "Current value of the loss function:  0.03565154181458788\n",
      "Current value of the loss function:  0.035651541854864535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.035651541854866145\n",
      "Current value of the loss function:  0.03565154183098\n",
      "Current value of the loss function:  0.03565154187646851\n",
      "Current value of the loss function:  0.035651541854866624\n",
      "Current value of the loss function:  0.0356515418548647\n",
      "Current value of the loss function:  0.035651541867310815\n",
      "Current value of the loss function:  0.03565154184450174\n",
      "Current value of the loss function:  0.03565154185486598\n",
      "Current value of the loss function:  0.03565154185486614\n",
      "Current value of the loss function:  0.03565154181354231\n",
      "Current value of the loss function:  0.035651541825996697\n",
      "Current value of the loss function:  0.03565154185486502\n",
      "Current value of the loss function:  0.03565154185486454\n",
      "Current value of the loss function:  0.03565154185486566\n",
      "Current value of the loss function:  0.03563332315044728\n",
      "Current value of the loss function:  0.03563332315416069\n",
      "Current value of the loss function:  0.03563332315379397\n",
      "Current value of the loss function:  0.03563332315042007\n",
      "Current value of the loss function:  0.03563332315044647\n",
      "Current value of the loss function:  0.0356333231504476\n",
      "Current value of the loss function:  0.03563332314964238\n",
      "Current value of the loss function:  0.035633323146679136\n",
      "Current value of the loss function:  0.03563332315044696\n",
      "Current value of the loss function:  0.035633323150446955\n",
      "Current value of the loss function:  0.03563332314971802\n",
      "Current value of the loss function:  0.03563332315510527\n",
      "Current value of the loss function:  0.03563332315044744\n",
      "Current value of the loss function:  0.035633323150447274\n",
      "Current value of the loss function:  0.03563332315037697\n",
      "Current value of the loss function:  0.035633323144308296\n",
      "Current value of the loss function:  0.03563332315044744\n",
      "Current value of the loss function:  0.035633323150447434\n",
      "Current value of the loss function:  0.03563332315051807\n",
      "Current value of the loss function:  0.03563332315123313\n",
      "Current value of the loss function:  0.03563332315044568\n",
      "Current value of the loss function:  0.0356333231504476\n",
      "Current value of the loss function:  0.03563332315321837\n",
      "Current value of the loss function:  0.03563332314391545\n",
      "Current value of the loss function:  0.035633323150448086\n",
      "Current value of the loss function:  0.0356333231504468\n",
      "Current value of the loss function:  0.035633323150098775\n",
      "Current value of the loss function:  0.03563332314892593\n",
      "Current value of the loss function:  0.035633323150446955\n",
      "Current value of the loss function:  0.03563332315044776\n",
      "Current value of the loss function:  0.035633323147181456\n",
      "Current value of the loss function:  0.035633323153019904\n",
      "Current value of the loss function:  0.035633323150446476\n",
      "Current value of the loss function:  0.035633323150448724\n",
      "Current value of the loss function:  0.035633323152303026\n",
      "Current value of the loss function:  0.035633323153595395\n",
      "Current value of the loss function:  0.03563332315044712\n",
      "Current value of the loss function:  0.03563332315044776\n",
      "Current value of the loss function:  0.035633323148562684\n",
      "Current value of the loss function:  0.03563332314745786\n",
      "Current value of the loss function:  0.03563332315044728\n",
      "Current value of the loss function:  0.035633323150448246\n",
      "Current value of the loss function:  0.03563332315044728\n",
      "Current value of the loss function:  0.0356331885743277\n",
      "Current value of the loss function:  0.03563318857347879\n",
      "Current value of the loss function:  0.03563318857469808\n",
      "Current value of the loss function:  0.03563318857523462\n",
      "Current value of the loss function:  0.03563318857432931\n",
      "Current value of the loss function:  0.03563318857432898\n",
      "Current value of the loss function:  0.03563318857381321\n",
      "Current value of the loss function:  0.03563318857374718\n",
      "Current value of the loss function:  0.035633188574326576\n",
      "Current value of the loss function:  0.035633188574328345\n",
      "Current value of the loss function:  0.035633188573579944\n",
      "Current value of the loss function:  0.03563318857564425\n",
      "Current value of the loss function:  0.03563318857432883\n",
      "Current value of the loss function:  0.0356331885743277\n",
      "Current value of the loss function:  0.035633188572977495\n",
      "Current value of the loss function:  0.03563318857340913\n",
      "Current value of the loss function:  0.03563318857432754\n",
      "Current value of the loss function:  0.035633188574326256\n",
      "Current value of the loss function:  0.035633188574249686\n",
      "Current value of the loss function:  0.03563318857294326\n",
      "Current value of the loss function:  0.03563318857432738\n",
      "Current value of the loss function:  0.03563318857432754\n",
      "Current value of the loss function:  0.03563318857531042\n",
      "Current value of the loss function:  0.035633188571166166\n",
      "Current value of the loss function:  0.0356331885743261\n",
      "Current value of the loss function:  0.035633188574328824\n",
      "Current value of the loss function:  0.035633188574468004\n",
      "Current value of the loss function:  0.03563318857434683\n",
      "Current value of the loss function:  0.035633188574328824\n",
      "Current value of the loss function:  0.035633188574327866\n",
      "Current value of the loss function:  0.03563318857404822\n",
      "Current value of the loss function:  0.03563318857328804\n",
      "Current value of the loss function:  0.035633188574328664\n",
      "Current value of the loss function:  0.035633188574328505\n",
      "Current value of the loss function:  0.035633188574821985\n",
      "Current value of the loss function:  0.03563318857376213\n",
      "Current value of the loss function:  0.035633188574326576\n",
      "Current value of the loss function:  0.03563318857432739\n",
      "Current value of the loss function:  0.03563318857364546\n",
      "Current value of the loss function:  0.035633188575774875\n",
      "Current value of the loss function:  0.03563318857432723\n",
      "Current value of the loss function:  0.03563318857432722\n",
      "Current value of the loss function:  0.0356331885743277\n",
      "Current value of the loss function:  0.03563318472324371\n",
      "Current value of the loss function:  0.03563318472298981\n",
      "Current value of the loss function:  0.035633184723371986\n",
      "Current value of the loss function:  0.035633184724147185\n",
      "Current value of the loss function:  0.03563318472324291\n",
      "Current value of the loss function:  0.03563318472324355\n",
      "Current value of the loss function:  0.035633184723385614\n",
      "Current value of the loss function:  0.03563318472321443\n",
      "Current value of the loss function:  0.03563318472324451\n",
      "Current value of the loss function:  0.03563318472324467\n",
      "Current value of the loss function:  0.03563318472249596\n",
      "Current value of the loss function:  0.03563318472481007\n",
      "Current value of the loss function:  0.03563318472324307\n",
      "Current value of the loss function:  0.03563318472324274\n",
      "Current value of the loss function:  0.03563318472299361\n",
      "Current value of the loss function:  0.03563318472159662\n",
      "Current value of the loss function:  0.035633184723241944\n",
      "Current value of the loss function:  0.03563318472324371\n",
      "Current value of the loss function:  0.03563318472318431\n",
      "Current value of the loss function:  0.035633184722994656\n",
      "Current value of the loss function:  0.03563318472324387\n",
      "Current value of the loss function:  0.03563318472324274\n",
      "Current value of the loss function:  0.03563318472398019\n",
      "Current value of the loss function:  0.035633184720496106\n",
      "Current value of the loss function:  0.03563318472324451\n",
      "Current value of the loss function:  0.03563318472324419\n",
      "Current value of the loss function:  0.03563318472298012\n",
      "Current value of the loss function:  0.03563318472365796\n",
      "Current value of the loss function:  0.035633184723244185\n",
      "Current value of the loss function:  0.0356331847232421\n",
      "Current value of the loss function:  0.03563318472252405\n",
      "Current value of the loss function:  0.03563318472244867\n",
      "Current value of the loss function:  0.03563318472324226\n",
      "Current value of the loss function:  0.03563318472324323\n",
      "Current value of the loss function:  0.035633184723408734\n",
      "Current value of the loss function:  0.035633184724179846\n",
      "Current value of the loss function:  0.0356331847232421\n",
      "Current value of the loss function:  0.03563318472324339\n",
      "Current value of the loss function:  0.03563318472333729\n",
      "Current value of the loss function:  0.035633184722515636\n",
      "Current value of the loss function:  0.03563318472324387\n",
      "Current value of the loss function:  0.03563318472324259\n",
      "Current value of the loss function:  0.03563318472324371\n",
      "Current value of the loss function:  0.03563318340498099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of the loss function:  0.03563318340485001\n",
      "Current value of the loss function:  0.03563318340499303\n",
      "Current value of the loss function:  0.03563318340578517\n",
      "Current value of the loss function:  0.03563318340498019\n",
      "Current value of the loss function:  0.03563318340497794\n",
      "Current value of the loss function:  0.03563318340510267\n",
      "Current value of the loss function:  0.035633183404876034\n",
      "Current value of the loss function:  0.03563318340498132\n",
      "Current value of the loss function:  0.03563318340498099\n",
      "Current value of the loss function:  0.03563318340423324\n",
      "Current value of the loss function:  0.03563318340647184\n",
      "Current value of the loss function:  0.035633183404981145\n",
      "Current value of the loss function:  0.035633183404982435\n",
      "Current value of the loss function:  0.03563318340441175\n",
      "Current value of the loss function:  0.03563318340349979\n",
      "Current value of the loss function:  0.035633183404982595\n",
      "Current value of the loss function:  0.03563318340498019\n",
      "Current value of the loss function:  0.03563318340496863\n",
      "Current value of the loss function:  0.0356331834046638\n",
      "Current value of the loss function:  0.03563318340498035\n",
      "Current value of the loss function:  0.035633183404980825\n",
      "Current value of the loss function:  0.035633183405817795\n",
      "Current value of the loss function:  0.03563318340241844\n",
      "Current value of the loss function:  0.035633183404981145\n",
      "Current value of the loss function:  0.03563318340498243\n",
      "Current value of the loss function:  0.03563318340472784\n",
      "Current value of the loss function:  0.03563318340546302\n",
      "Current value of the loss function:  0.03563318340498002\n",
      "Current value of the loss function:  0.03563318340498099\n",
      "Current value of the loss function:  0.0356331834042358\n",
      "Current value of the loss function:  0.03563318340408415\n",
      "Current value of the loss function:  0.03563318340498147\n",
      "Current value of the loss function:  0.035633183404980666\n",
      "Current value of the loss function:  0.035633183404986446\n",
      "Current value of the loss function:  0.03563318340570336\n",
      "Current value of the loss function:  0.03563318340498019\n",
      "Current value of the loss function:  0.035633183404980506\n",
      "Current value of the loss function:  0.03563318340502851\n",
      "Current value of the loss function:  0.03563318340446445\n",
      "Current value of the loss function:  0.03563318340498163\n",
      "Current value of the loss function:  0.03563318340498116\n",
      "Current value of the loss function:  0.03563318340498099\n",
      "Current value of the loss function:  0.03563318087521787\n",
      "Current value of the loss function:  0.035633180875181886\n",
      "Current value of the loss function:  0.035633180875121385\n",
      "Current value of the loss function:  0.035633180875948016\n",
      "Current value of the loss function:  0.03563318087521996\n",
      "Current value of the loss function:  0.03563318087521851\n",
      "Current value of the loss function:  0.03563318087534581\n",
      "Current value of the loss function:  0.0356331808750408\n",
      "Current value of the loss function:  0.0356331808752198\n",
      "Current value of the loss function:  0.03563318087521963\n",
      "Current value of the loss function:  0.035633180874469636\n",
      "Current value of the loss function:  0.035633180876598225\n",
      "Current value of the loss function:  0.035633180875217545\n",
      "Current value of the loss function:  0.03563318087521964\n",
      "Current value of the loss function:  0.03563318087444508\n",
      "Current value of the loss function:  0.0356331808738633\n",
      "Current value of the loss function:  0.03563318087521979\n",
      "Current value of the loss function:  0.035633180875218516\n",
      "Current value of the loss function:  0.03563318087527678\n",
      "Current value of the loss function:  0.03563318087487457\n",
      "Current value of the loss function:  0.03563318087521787\n",
      "Current value of the loss function:  0.03563318087521963\n",
      "Current value of the loss function:  0.03563318087614842\n",
      "Current value of the loss function:  0.035633180872804045\n",
      "Current value of the loss function:  0.035633180875217225\n",
      "Current value of the loss function:  0.03563318087521851\n"
     ]
    }
   ],
   "source": [
    "## Training the QNN using gradient-based optimizer\n",
    "nBits = 10 # number of bits per feature\n",
    "\n",
    "## Random training set consisting of 11 10-bit features\n",
    "## Please explore other training sets\n",
    "trainSet = ['1101011010','1000110011','0101001001','0010000110','0101111010','0000100010','1001010000','1100110001','1000010001','0000111101','0000000001']\n",
    "\n",
    "## Initial assignment of QNN parameters theta and phi (random angles in [-pi,pi]) \n",
    "pars0 = 2 * np.pi * np.random.rand((4*nBits+1)+1) - np.pi\n",
    "\n",
    "## Run minimization\n",
    "res = minimize(lambda pars: cost(trainSet,pars,device), pars0, method='BFGS', options={'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.14159181,  1.57079645,  1.57079594, -2.46601843,  1.34899684,\n",
       "        1.57079613, -1.57079532, -1.03040034,  3.00384032, -1.57079552,\n",
       "       -1.57079364,  2.37900951,  1.90661499, -4.71238941, -4.71238827,\n",
       "        0.58088184, -0.81304186,  1.57079629, -1.57079689, -0.7949282 ,\n",
       "        0.35072509, -1.57079625,  4.71238891, -3.04443264,  0.60414274,\n",
       "        1.57079636,  1.57079449,  1.22825087,  2.71286404,  1.57079642,\n",
       "       -1.57079428,  0.68278081, -1.17856405, -1.57079599, -1.57079722,\n",
       "       -1.54733172, -1.49995763, -1.5707964 ,  1.57079567, -1.14955359,\n",
       "        1.65433388,  0.81147166])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code wait for the optimizer to converge. It will output a message that will look like this when the optimizer finishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization terminated successfully.\n",
    "         Current function value: 0.000000\n",
    "         Iterations: 83\n",
    "         Function evaluations: 4515\n",
    "         Gradient evaluations: 105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the loss function value is not zero it means that the optimizer got stuck in a local minimum. It is possible because $\\langle\\hat{Z}\\rangle(\\{\\vec{\\theta},\\vec{\\phi}\\})$ is not a convex function of the parameters $\\theta$ and $\\phi$. Do not panic. Try running the optimizer with a different set of initial parameters ${\\rm pars0}$. In general, it is a good idea to run a batch of optimizers with different initial conditions and select the one that achieves the smallest value of the loss function. One can also explore various minimization algorithms by specifying method='' in the minimize function.\n",
    "\n",
    "Calling res.x will output the optimal values of the parameters $\\theta$ and $\\phi$ and we can use them to run the optimal quantum neural net on the features that are not in the training set. Try that and compute the mean square error of the classifier.\n",
    "\n",
    "For the 10-bit feature example here there is $2^{10}=1024$ possible features, we chose a training set that has only 11 features. Yet it is sufficiently large to train the quantum neural net to act as a perfect binary classifier for all 1024 possible features. Can you demonstrate that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0000000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000001 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100010 | QNN predicted parity:  0.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111101 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0000111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0001000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0001111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010000110 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0010000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0010111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0011001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0011111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0100001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0100111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001001 | QNN predicted parity:  0.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0101010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111010 | QNN predicted parity:  0.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0101111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0110010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0110111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0111011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 0111111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010001 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1000100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110011 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1000111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010000 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1001101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1001111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1010110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1010111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1011110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1011111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110001 | QNN predicted parity:  1.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1100111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1100111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011010 | QNN predicted parity:  0.0  |  in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1101111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1110000101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110000111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110001111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110010111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110011111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110100111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110101111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110110111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1110111111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111000111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1111001000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111001111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111010111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111011111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111100111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111101111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110000 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110001 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110010 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110011 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110100 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110101 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110110 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111110111 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111000 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111001 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111010 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111011 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111100 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111101 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111110 | QNN predicted parity:  1.0  |  NOT in the training set\n",
      "---------------------------------------------------\n",
      "Feature: 1111111111 | QNN predicted parity:  0.0  |  NOT in the training set\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Print the predicted label values for all N-bit features using the optimal QNN parameters res.x\n",
    "for ind in range(2**nBits):\n",
    "    task = device.run(QNN(format(ind, '0'+str(nBits)+'b'),res.x), shots=100)\n",
    "    result = task.result()\n",
    "    if (format(ind, '0'+str(nBits)+'b') in trainSet):\n",
    "        inSet = 'in the training set'\n",
    "    else:\n",
    "        inSet = 'NOT in the training set'\n",
    "    print('Feature:', format(ind, '0'+str(nBits)+'b'), '| QNN predicted parity: ', 0.5*(1-result.values[0]), ' | ', inSet) \n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
